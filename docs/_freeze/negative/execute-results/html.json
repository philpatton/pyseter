{
  "hash": "6a1aa340584ac6d8431821938bab5f55",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Computing false negative rates\nbibliography: references.bib\njupyter:\n  kernelspec:\n    display_name: Python (Pyseter)\n    language: python\n    name: pyseter_env\nexecute:\n  cache: true\n---\n\nA subtle but important choice when deciding how to automate photo-ID is the number of proposed matches you are going to evaluate before deciding that an individual is new to the dataset. An algorithm optimist might argue that you just need to check the first proposed ID to make sure it's not a false positive (i.e., claiming two distinct individuals are one). An algorithm skeptic might argue that you need to check every proposed ID, i.e., every individual in the reference set, before adding a new individual to the dataset.\n\nWe can reframe this debate in terms of false negative rates. A false negative occurs when you didn't look far enough down the list of proposed IDs, and added a new individual that already existed in the dataset. Our algorithm optimist is arguing that the algorithm won't produce false negatives, or they aren't important. Our algorithm skeptic is arguing that the algorithm will produce false negatives and that false negatives are critical.\n\nThe skeptic is right in that false negatives are critically important. An 8% false negative rate might seem small, but it suggests that you will overestimate your population size by 20% [@patton-2025-optimizing]. This overestimation can have grim consequences if, say, the estimate is used to compute potential biological removal.\n\nEither the skeptic or the optimist could be right about the prevalence of false negatives. But why trust them, when we can estimate them ourselves?\n\n## Dataset\n\nTo demonstrate how to compute false negative rates, we'll use the [Happy Whale and Dolphin Kaggle competition dataset](https://www.kaggle.com/competitions/happy-whale-and-dolphin/data) as an example. You can download the data by following that linked page (click the big \"Download all\" button). FYI, you'll have to create an account first.\n\n::: {#d6c09a0d .cell execution_count=2}\n``` {.python .cell-code}\nfrom pyseter.sort import load_features\nfrom pyseter.identify import predict_ids\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef where(list, value):\n    \"\"\"Where in the list is the \"\"\"\n    try:\n        return (list.index(value) + 1)\n    except ValueError:\n        return np.nan\n\n# load in the feature vectors\ndata_dir = '/Users/PattonP/datasets/happywhale/'\nfeature_dir = data_dir + '/features'\n\nreference_path = feature_dir + '/train_features.npy'\nreference_files, reference_features = load_features(reference_path)\n\nquery_path = feature_dir + '/test_features.npy'\nquery_files, query_features = load_features(query_path)\n\n# get the IDs for every individual in the happywhale set\ndata_url = (\n    'https://raw.githubusercontent.com/philpatton/pyseter/main/' \n    'data/happywhale-ids.csv'\n)\nid_df = pd.read_csv(data_url)\n\nid_df = id_df.set_index('image')\nid_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>species</th>\n      <th>individual_id</th>\n    </tr>\n    <tr>\n      <th>image</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000110707af0ba.jpg</th>\n      <td>gray_whale</td>\n      <td>fbe2b15b5481</td>\n    </tr>\n    <tr>\n      <th>00021adfb725ed.jpg</th>\n      <td>melon_headed_whale</td>\n      <td>cadddb1636b9</td>\n    </tr>\n    <tr>\n      <th>000562241d384d.jpg</th>\n      <td>humpback_whale</td>\n      <td>1a71fbb72250</td>\n    </tr>\n    <tr>\n      <th>0006287ec424cb.jpg</th>\n      <td>false_killer_whale</td>\n      <td>1424c7fec826</td>\n    </tr>\n    <tr>\n      <th>0007c33415ce37.jpg</th>\n      <td>false_killer_whale</td>\n      <td>60008f293a2b</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#31dd7b68 .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\n# excel on mac corrupts the IDs (no need to do this on PC or linux)\nid_df['individual_id'] = id_df['individual_id'].apply(\n    lambda x: str(int(float(x))) if 'E+' in str(x) else x\n)\n```\n:::\n\n\n## Predicting IDs\n\nWe're also going to peek under the hood of [identify.predict_ids](api/identify.predict_ids.qmd). This is helpful because the number of proposed IDs will vary a lot with such a large and diverse dataset as the Happywhale dataset. \n\n::: {#b2a9f274 .cell execution_count=4}\n``` {.python .cell-code}\nfrom pyseter.identify import find_neighbors, insert_new_id, pool_predictions\nimport numpy as np\n\n# this is the true id of every id in the reference dataset\nids = id_df.loc[reference_files, 'individual_id'].to_numpy()\n\n# takes about 19 seconds\ndistance_matrix, index_matrix = find_neighbors(reference_features, query_features)\n\n# get the corresponding labels for each reference image\npredicted_ids = ids[index_matrix]\n\n# insert the prediction \"new_individual\" at the threshold\ndistances, ids = insert_new_id(distance_matrix, predicted_ids, threshold=0.5)\n\n# remove redundant predictions and take the minimum distance \npooled_distances, pooled_ids = pool_predictions(ids, distances)\n```\n:::\n\n\nNow we want to find where in the `pooled_ids` is the true identity of the animal. If the algorithm's first guess was right, then this value should be `1`. As such, we are finding the rank of the correct guess for each query image. \n\n::: {#0114334f .cell execution_count=5}\n``` {.python .cell-code}\nrecords = []\nfor i, image in enumerate(query_files):\n\n    # where is the true id in the list of predicted IDs?\n    true_id = id_df.loc[image]['individual_id']\n    rank = where(pooled_ids[i].tolist(), true_id)\n\n    # these will become the rows in our dataframe\n    records.append({'image': image, 'rank': rank})\n\ndf = pd.DataFrame.from_records(records).set_index('image').join(id_df)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>species</th>\n      <th>individual_id</th>\n    </tr>\n    <tr>\n      <th>image</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a704da09e32dc3.jpg</th>\n      <td>5.0</td>\n      <td>frasiers_dolphin</td>\n      <td>43dad7ffa3c7</td>\n    </tr>\n    <tr>\n      <th>de1569496d42f4.jpg</th>\n      <td>1.0</td>\n      <td>pilot_whale</td>\n      <td>ed237f7c2165</td>\n    </tr>\n    <tr>\n      <th>4ab51dd663dd29.jpg</th>\n      <td>1.0</td>\n      <td>beluga</td>\n      <td>b9b24be2d5ae</td>\n    </tr>\n    <tr>\n      <th>da27c3f9f96504.jpg</th>\n      <td>1.0</td>\n      <td>bottlenose_dolpin</td>\n      <td>c02b7ad6faa0</td>\n    </tr>\n    <tr>\n      <th>0df089463bfd6b.jpg</th>\n      <td>3.0</td>\n      <td>dusky_dolphin</td>\n      <td>new_individual</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSo in the case of the dusky dolphin image, `0df089463bfd6b.jpg`, the algorithm's first two guesses were that this individual was in the reference set, when in reality it was new to the reference set.\n\n## Computing false negative rates\n\nNow we want to understand what our false negative rate would have been had we tried different strategies. These strategies, `proposed_id_count`, correspond to the arguments between the AI skeptic and the AI optimist. At one extreme, we only look at the first proposed ID. At the other, we look through the first 25 proposed IDs. Here, we assume that there are no false positive matches. \n\nFor fun, we'll look at the average across species. Note that this is a naive approach, because the algorithm's performance can vary widely across catalogs for the same species [@patton-2023-deep].\n\n::: {#c9cf5203 .cell execution_count=6}\n``` {.python .cell-code}\ndf_list = []\n\n# how many of the proposed ids did you check?\nfor proposed_id_count in range(1, 26):\n\n    # was the true id further down the list?\n    # i.e., had you kept looking would you have found it?\n    missed_match = df['rank'] > proposed_id_count\n\n    # is this individual in the reference set? we're assuming no false positives\n    not_new = df['individual_id'] != 'new_individual'\n\n    # if both are true, then you committed a false negative error\n    df['error'] = missed_match & not_new\n\n    # compute the average for each species \n    fn_df = df.groupby('species')['error'].mean().rename('fn_rate').reset_index()\n    fn_df['proposed_id_count'] = proposed_id_count\n    \n    df_list.append(fn_df)\n```\n:::\n\n\nWe can translate these false negative rates into expected relative bias in our estimate of the total population size. A relative bias of 10% means that we overestimate the population by 10%. For every one percentage point increase in the false negative rate, our relative bias increases by 2.56 percentage points [@patton-2025-optimizing]. We're going to exclude the Fraser's dolphin catalog, which had extremely poor performance.\n\n::: {#e4da177d .cell execution_count=7}\n``` {.python .cell-code}\nfn_df = pd.concat(df_list)\nfn_df['rbias'] = fn_df['fn_rate'] * 2.56\nfn_df = fn_df.loc[fn_df['species'] != 'frasiers_dolphin'].reset_index()\n```\n:::\n\n\nNow we can plot the results for each species. We've highlighted five randomly selected species to reduce over plotting. \n\n::: {#db19373a .cell execution_count=8}\n``` {.python .cell-code code-fold=\"true\"}\nspecials = fn_df.sample(5, random_state=10).species.unique()\nspecial_df = fn_df.loc[fn_df.species.isin(specials)]\nnonspecial_df = fn_df.loc[~fn_df.species.isin(specials)]\n\nfig, ax = plt.subplots(figsize = (7, 5), tight_layout=True)\n\nfor name, df in nonspecial_df.groupby('species'):\n    ax.plot(df.proposed_id_count, df.rbias, alpha=0.3, c='tab:grey', zorder=-2)\n\nfor name, df in special_df.groupby('species'):\n    ax.plot(df.proposed_id_count, df.rbias, label=name.replace('_', ' '), linewidth=2.5)\n\nimport matplotlib.ticker as mtick\nax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n\nax.set_ylabel(r'Relative bias in $N$', fontsize=14)\nax.set_xlabel(r'Proposed IDs checked', fontsize=14)\nax.set_ylim((0, 0.6))\n\nax.spines[:].set_visible(False)\n\nax.xaxis.tick_bottom()\nax.yaxis.tick_left()\n\nax.grid(True, 'major', 'both', ls='--', lw=.5, c='k', alpha=.3)\n\nax.tick_params(axis='both', which='both', labelsize='large',\n               bottom=False, top=False, labelbottom=True,\n               left=False, right=False, labelleft=True)\n\nax.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](negative_files/figure-html/cell-8-output-1.png){width=662 height=470}\n:::\n:::\n\n\nWe can see that most species get below 10% once we've checked up to 10 proposed matches. In fact, 26 of the 39 datasets achieved a relative bias less than 10% at 10 proposed matches [@patton-2025-optimizing]. \n\nOne important caveat that could be depressing performance is that, in this case, we're matching against all species. As such, the 8th, 9th, 10th, proposed ID for a long-finned pilot whale may indeed by a short-finned pilot whale. In real life, biologists will know not to match against the wrong species. Correcting for this would decrease the false negative rate for all species. \n\n",
    "supporting": [
      "negative_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}