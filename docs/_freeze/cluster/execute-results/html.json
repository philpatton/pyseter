{
  "hash": "14969ab8392a747628b8edd7a7322c2d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Clustering individuals\njupyter:\n  kernelspec:\n    display_name: Python (Pyseter)\n    language: python\n    name: pyseter_env\n---\n\nHere we present a quick overview on how to cluster individuals with Pyseter. Clustering individuals is useful when you don't want to match against a reference set. For example, you might want to quickly sort individuals from the field into folders of proposed IDs, such that you can quickly grade the images for quality and distinctiveness. \n\nPyseter comes with two ways to cluster individuals: `NetworkCluster` and `HierarchicalCluster`. `NetworkCluster` is most useful for smaller datasets, and should be intuitive for anyone who has worked with similarity scores before. `HierarchicalCluster` works better for larger datasets.\n\n::: {#350328bc .cell execution_count=1}\n``` {.python .cell-code}\nimport os\n\nfrom pyseter import sort\nfrom sklearn.metrics.pairwise import cosine_similarity\n```\n:::\n\n\n## Dataset\n\nTo demonstrate clustering, we'll use the spinner dolphin example dataset. The images in this example were collected during a multi-year photo-ID survey of spinner dolphins in Hawai ªi. We demonstrate how to extract the features and save them for this dataset in [Extracting Features](extract.qmd). As such, we'll load the previously saved features here. \n\n::: {#ac09b84c .cell execution_count=2}\n``` {.python .cell-code}\nfeature_dir = 'working_dir/features'\nout_path = feature_dir + '/features.npy'\nfilenames, feature_array = sort.load_features(out_path)\n```\n:::\n\n\n## Network clustering\n\nIf an ID algorithm is calibrated correctly, then a high similarity score between two images should indicate a high probability that they contain the same individual. As such, we might define a threshold, over which we assume that two images contain the same individual. Once we compute the similarity scores between all pairs of images, we can look to see which images are \"connected\", that is, which pairs of images have a similarity score over a threshold. When multiple images are connected to one another in a blob, we can consider them a proposed ID. The end result of all this is a network, where the images are the \"nodes\" and similarity scores over the threshold are the \"edges\". The number of clusters, that is, the number of sets of nodes that have connections between them, represents the number of proposed IDs.\n\nThe number of clusters depends on the `match_threshold`. Low thresholds will create many connections and therefore few clusters. High thresholds will create few connections and therefore many clusters. The ideal threshold will depend on the dataset. We think 0.55 is a nice middle ground for most applications. \n\nTo do the network matching, we just need to compute the pairwise similarity between images. We will use `cosine_similarity` from `sklearn.metrics.pairwise` to do so. `cosine_similarity` similarity returns an $m$ by $m$ matrix of similarity scores where $m$ is the number of proposed IDs.\n\n::: {#221d4238 .cell execution_count=3}\n``` {.python .cell-code}\nsimilarity_scores = cosine_similarity(feature_array)\nnc = sort.NetworkCluster(match_threshold=0.55)\nresults = nc.cluster_images(similarity_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFollowing clusters may contain false positives:\n['ID_0001', 'ID_0006', 'ID_0008', 'ID_0021', 'ID_0110']\n```\n:::\n:::\n\n\nWe can do a quick sanity check on our match threshold with `report_cluster_results`, which tells us how many clusters there are and which one is the largest. \n\n::: {#d35ad1d2 .cell execution_count=4}\n``` {.python .cell-code}\nnetwork_idx = results.cluster_idx\nsort.report_cluster_results(network_idx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound 208 clusters.\nLargest cluster has 128 images.\n```\n:::\n:::\n\n\n`cluster_images` tells us that some of the proposed IDs (i.e., clusters) might contain false positives. False positives occur when two distinct individuals are grouped within the same cluster. While we don't know the truth, we can look for evidence of such errors. Imagine that two images looks somewhat similar to each other, and are therefore connected. But each one, in turn, looks very similar to other images. As such, the cluster looks like a barbell, with one spurious connection between two highly connected blobs. We can look for such clusters with `plot_suspicious`\n\n::: {#ba9f74c5 .cell execution_count=5}\n``` {.python .cell-code}\nresults.plot_suspicious()\n```\n\n::: {.cell-output .cell-output-display}\n![](cluster_files/figure-html/cell-6-output-1.png){width=710 height=146}\n:::\n:::\n\n\nOf these, cluster `ID_0001` is probably the most suspicious, and worthy of investigating. Note that dataset includes indistinct individuals, which tend to cluster together. `ID_0008` most likely contains many of the indistinct individuals. \n\nAs the number of image in the dataset grows, network clustering becomes impractical because false positives and suspicious clusters will pervade. For larger datasets, we recommend hierarchical clustering\n\n## Hierarchical clustering\n\nHierarchical clustering works better for larger datasets. Hierarchical clustering works by clustering feature vectors together with a dendrogram. You can read more about hierarchical clustering in the [scikit-learn user guide](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering), which has a thorough guide to clustering algorithms. Pyseter's `HierarchicalCluster` is a wrapper for scikit-learn's implementation\n\nWe recommend setting the `match_threshold` threshold slightly lower for `HierarchicalCluster`, e.g., 0.5 \n\n::: {#c4e582a0 .cell execution_count=6}\n``` {.python .cell-code}\nhc = sort.HierarchicalCluster(match_threshold=0.5)\nhac_idx = hc.cluster_images(feature_array)\n\n# format_ids converts the integer labels to something like 'ID-0001'\nhac_labels = sort.format_ids(hac_idx)\nsort.report_cluster_results(hac_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound 299 clusters.\nLargest cluster has 27 images.\n```\n:::\n:::\n\n\nWe see that `HierarchicalCluster` produces more clusters, i.e., more proposed IDs. As such, expect `HierarchicalCluster` to be much sparser in most cases. \n\n",
    "supporting": [
      "cluster_files"
    ],
    "filters": [],
    "includes": {}
  }
}