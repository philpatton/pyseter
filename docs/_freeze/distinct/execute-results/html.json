{
  "hash": "c86c2800a58abb33484219cd231c0ad8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Grading distinctiveness\nbibliography: references.bib\njupyter: python3\n---\n\nPyseter comes with an experimental algorithm for grading individual distinctiveness. This can be useful for partially marked populations, e.g., spinner dolphins. \n\n## Background\n\nTo understand the distinctiveness algorithm, it can be helpful to first introduce one of Pyseter’s clustering algorithms, `NetworkCluster`. Network clustering works with similarity scores, which represent the similarity between two individuals in a pair of images. We can define a threshold score, the `match_threshold`, above which we consider two individuals to be the same. That is, if the similarity score between two images is above a certain threshold, we cluster them into a proposed ID. As such, network clustering works by treating the query set as a network, where the nodes are images and the edges are similarity scores above a threshold. Each set of connected components, i.e., images whose similarity scores are above the match threshold, represents a proposed ID.\n\nWe might expect the indistinct individuals to cluster together. In the context of facial recognition, @deng-2023-ui observed that “unrecognizable identities”, e.g., extremely blurry or masked faces, tend to cluster together. As such, for partially marked populations, the largest cluster in the query set may represent every indistinct individual. Following @deng-2023-ui, we can compute the average feature vector for this cluster. The distance between this average feature vector and the feature vector for each image is the distinctiveness score for that image. As such, the score applies to the image, not the animal. To get a score for an animal, users could average the distinctiveness scores across images for that animal.\n\n## Spinner dolphin example\n\nThe images in this example were collected during a multi-year photo-ID survey of spinner dolphins in Hawaiʻi. We'll load in the saved feature vectors from before. \n\n::: {#239ccfe3 .cell execution_count=1}\n``` {.python .cell-code}\n%config InlineBackend.figure_format = 'retina'\n\nfrom PIL import Image\nfrom pyseter.grade import rate_distinctiveness\nfrom pyseter.sort import load_features\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# load the features\nfeature_dir = 'working_dir/features'\nout_path = feature_dir + '/features.npy'\nfilenames, feature_array = load_features(out_path)\n```\n:::\n\n\nWe need to supply two arguments to `rate_distinctiveness`: the `feature_array`, and the `match_threshold`. The lower the match threshold, the more individuals will end up in the unrecognizable identity cluster, potentially including distinct individuals. Conversely, a high match threshold might split the indistinct individuals into many clusters. \n\n::: {#1fd7862e .cell execution_count=2}\n``` {.python .cell-code}\ndistinctiveness = rate_distinctiveness(feature_array, match_threshold=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnrecognizable identity cluster consists of 196 images.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/PattonP/miniforge3/envs/pyseter_env/lib/python3.14/site-packages/pyseter/grade.py:35: UserWarning: Distinctiveness grades are experimental and should be verified.\n  warn(UserWarning('Distinctiveness grades are experimental and should be verified.'))\n```\n:::\n:::\n\n\n`rate_distinctiveness` warns you that this is experimental, and lets you know how many individuals ended up in the unrecognizable identity. This should be a quick sanity check. \n\nWe can plot the results of the score with the receiver operator characteristic (ROC) curve. This treats the distinctiveness grade as a classifier probability. The area under the curve tells us how good the classifier is, i.e., in terms of the number of false positives and false negatives. \n\n::: {#95082c9f .cell execution_count=3}\n``` {.python .cell-code}\n# download the true distinctiveness scores\ndata_url = (\n    'https://raw.githubusercontent.com/philpatton/pyseter/main/' \n    'data/spinner-distinct.csv'\n)\nspinner_distinct = pd.read_csv(data_url)\n\n# merge with the predicted distinctiveness scores\ners_df = pd.DataFrame({'image': filenames, 'ers': distinctiveness})\ners_df = ers_df.merge(spinner_distinct)\n\n# convert distinctiveness to binary outcome such that d1-d2 -> 1\ny_score = ers_df['ers']\ny_test, _ =  ers_df.distinctiveness.factorize()\ny_test = 1 - y_test\n\nfig, ax = plt.subplots(figsize=(5, 4))\n\nax.hist(y_score[y_test == 1], bins=20, ec='w', alpha=0.7, label='Distinctive')\nax.hist(y_score[y_test == 0], bins=20, ec='w', alpha=0.7, label='Not distinctive')\n\nax.legend()\n\nax.spines[['right', 'top']].set_visible(False)\n\nax.set_xlabel('Embedding recognizability score (ERS)')\nax.set_ylabel('Number of images')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Histogram of ERS scores for images of distinctive (blue bars) and not distinctive (orange bars) individuals.](distinct_files/figure-html/cell-4-output-1.png){width=444 height=356}\n:::\n:::\n\n\nImages of not distinctive individuals (orange bars) rarely have a high ERS. For example, 2.4% of indistinct individuals and 42% of distinct individuals have an ERS greater than 0.8. We can look at the outlier images of indistinct individuals with a high ERS.\n\n::: {#cell-fig-hist .cell execution_count=4}\n``` {.python .cell-code}\noutliers = ers_df.loc[(ers_df.distinctiveness == 'd3-d4') & (ers_df.ers > 0.8), 'image']\nfig, axes = plt.subplots(3, 2, figsize=(8, 9))\n\nfor i, image in enumerate(outliers):\n    ax = axes.flat[i]\n    path = 'working_dir/all_images/' + image\n    img = Image.open(path)\n    ax.imshow(img)\n    ax.axis('off')\n\naxes[2, 1].remove()\nfig.suptitle('Indistinct individuals ERS > 0.8')\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![The five images with an ERS over 0.8, yet had been manually classified as containing an not distinctive individual.](distinct_files/figure-html/fig-hist-output-1.png){#fig-hist width=758 height=840}\n:::\n:::\n\n\nOne of the images (top left) is clearly a cropping error. Two of the images depict an individual with some rake marks across the dorsal fin that *AnyDorsal* might be keying in on. The individual in the middle right does have some notches along its fin. It's unclear what *AnyDorsal* sees in the image in the upper right hand corner\n\nAdditionally, we can see that distinctive individuals (blue) rarely have a low ERS [@fig-hist]. While 0.57% of distinct individuals and have an ERS less than 0.5, that number is 43% for indistinct individuals. We can look at the six outlier distinctive individuals with an ERS below 0.5.\n\n::: {#2d6b89dd .cell execution_count=5}\n``` {.python .cell-code}\noutliers = ers_df.loc[(ers_df.distinctiveness == 'd1-d2') & (ers_df.ers < 0.5), 'image']\nfig, axes = plt.subplots(3, 2, figsize=(8, 9))\n\nfor i, image in enumerate(outliers):\n    ax = axes.flat[i]\n    path = 'working_dir/all_images/' + image\n    img = Image.open(path)\n    ax.imshow(img)\n    ax.axis('off')\n\nfig.suptitle('Distinctive individuals with ERS < 0.5')\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![The six images with an ERS below 0.5, yet had been manually classified as containing a distinctive individual.](distinct_files/figure-html/cell-6-output-1.png){width=758 height=840}\n:::\n:::\n\n\nThe images show relatively clean fins but with certain characteristics (e.g., fin shape), that stood out to human reviewers as distinctive enough for classification.\n\nAnother way to assess the usefulness of the ERS is to treat it as a classifier where $I(\\mathrm{ers} > \\tau) = 1$ for some threshold $\\tau$. We can evaluate the classifier with an ROC curve.\n\n::: {#8ee3209b .cell execution_count=6}\n``` {.python .cell-code}\ndisplay = RocCurveDisplay.from_predictions(\n    y_test, y_score, name=\"ERS\", plot_chance_level=True, despine=True\n)\n\nfig = display.figure_\nfig.set_size_inches(5, 5)\nax = display.ax_.axes\nax.set_title('ROC curve for ERS classifier of distinctiveness')\nax.set_ylabel('True positive rate (Positive label: Distinctive)')\nax.set_xlabel('False positive rate (Positive label: Distinctive)')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Receiver operator characteristic (ROC) curve (blue line) for a classifier that classifies the image as containing a distinct individual with the ERS score. The chance level (dashed line) randomly classifies the image.](distinct_files/figure-html/cell-7-output-1.png){width=445 height=449}\n:::\n:::\n\n\nWe can see that the classifier achieves an AUC of 0.92, outperforming the random classifier (AUC = 0.5). The true positive rate grow rapidly initially because there are so few distinct individuals with low ERS  [@fig-hist]. Then, the curve begins to sag a bit as it enters the area of overlap between 0.4 and 0.6 ERS [@fig-hist].\n\nWe can also try to visualize the feature vectors with UMAP [@mcinnes-2018-umap]. Interpreting UMAP is a minefield of caveats, but it can be a useful visualization technique for extremely high dimensional spaces. The feature vectors reside on a 5,504 dimensional hypersphere. \n\n::: {#3e2a976b .cell execution_count=7}\n``` {.python .cell-code}\nimport umap\n\n# project the embeddings with UMAP\nembedding = umap.UMAP(\n    min_dist = 0.55, n_neighbors=25, metric='cosine'\n).fit_transform(feature_array)\n\n\nfig, ax = plt.subplots(figsize=(5, 5), tight_layout=True)\n\nindistinct = embedding[y_test == 0]\nax.scatter(indistinct[:, 0], indistinct[:, 1], s=5, label='Not Distinctive', \n           color='C1', zorder=2)\n\ndistinct = embedding[y_test == 1]\nax.scatter(distinct[:, 0], distinct[:, 1], s=5, label='Distinctive', color='C0', \n           zorder=-2, alpha=0.8)\n\nax.set_xticks([])\nax.set_yticks([])\nax.legend()\n\nax.set_title(f'UMAP projection of feature vectors')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![UMAP projection of feature vectors for images of not distinctive (orange dots) and distinctive (blue dots) individuals.](distinct_files/figure-html/cell-8-output-1.png){width=470 height=470}\n:::\n:::\n\n\nUMAP echoes our previous results, namely, that the embeddings for the not distinctive individuals tend to cluster together. There is, however, substantial overlap, and there are a few not distinctive embeddings lingering where they shouldn't (at least theoretically). \n\n:::{.callout-warning}\nUsers will need to install [umap-learn](https://umap-learn.readthedocs.io/en/latest/), e.g., `conda install umap-learn -c conda-forge`, to run the above code block\n:::\n\n",
    "supporting": [
      "distinct_files"
    ],
    "filters": [],
    "includes": {}
  }
}