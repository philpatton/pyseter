{
  "hash": "9267a2fb865ea112e951529ac8000257",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Identify App\njupyter:\n  kernelspec:\n    display_name: Python (Pyseter)\n    language: python\n    name: pyseter_env\nexecute:\n  cache: true\n---\n\nPyseter ships with an experimental app that allows users to click through proposed IDs, identify matches, and export the results of the identification via a .csv. It's worth reiterating that this is an experimental feature and, as such, is pretty bare bones. Nevertheless, we hope people will find it useful and suggest ways it could be improved. \n\nThis notebook will demonstrate how to run the app locally, and show users a demo version of the app. Running the code below will launch a version of the app based on the Happywhale data, where the test images are the \"query set\" and the training images are the \"reference set\". The demo version is hosted on Hugging Face, and represents a subset of the Happywhale dataset. \n\n## Launching the app locally \n\nHere we'll assume that you've already extracted the features for the query images and the reference images. As such, we can just load them in. \n\n::: {#781dadb8 .cell execution_count=1}\n``` {.python .cell-code}\nfrom pyseter.experimental import launch_review\nfrom pyseter.identify import predict_ids\nfrom pyseter.sort import load_features\nimport pandas as pd\n\ndata_dir = '/Users/PattonP/datasets/happywhale/'\n\nfeature_dir = data_dir + '/features'\n\nreference_path = feature_dir + '/train_features.npy'\nreference_files, reference_features = load_features(reference_path)\n\nquery_path = feature_dir + '/test_features.npy'\nquery_files, query_features = load_features(query_path)\n\nid_df = pd.read_csv(data_dir + '/train.csv')\n```\n:::\n\n\nThen we'll create dictionaries for the reference set and the query set. These dictionaries map the file names to the feature vectors. Once we've done that, we can predict the 5 closest IDs in the query set to that of the reference set.  \n\n::: {#136e2f7e .cell execution_count=2}\n``` {.python .cell-code}\nquery_dict = dict(zip(query_files, query_features))\nreference_dict = dict(zip(reference_files, reference_features))\n\nprediction_df = predict_ids(reference_dict, query_dict, id_df, proposed_id_count=5)\n```\n:::\n\n\nNow we have all we need to launch the app: the data frame containing the predictions, `prediction_df`; the data frame containing the IDs for images in the reference set, `id_df`; the directory containing the query images; and the directory containing the test images. \n\n::: {#4bfc824f .cell execution_count=3}\n``` {.python .cell-code}\nlaunch_review(\n    prediction_df,\n    id_df,\n    data_dir + '/test_images'\n    data_dir + '/train_images'\n)\n```\n:::\n\n\n## Demo version\n\nHere, we demonstrate what the app looks like when you run it locally. This demo version contains 68 images from the Happywhale dataset, and represents a roughly even sample of every catalog in the dataset. \n\n<iframe\n\tsrc=\"https://pattonp-pyseter-app-demo.hf.space\"\n\tframeborder=\"0\"\n\twidth=\"100%\"\n\theight=\"800px\"\n></iframe>\n\nHere are a few pointers on how to use the app\n\n- **Next** and **Prev** navigate between query images\n- You can navigate between reference images of proposed IDs with the left and right arrow keys\n- The radio buttons under *Select correct match* allow you to select which proposed ID best matches the query image, if any\n- **Confirm match** locks in your choice\n- **Download csv** downloads a .csv where one column is the query image and the other column is the confirmed ID\n- Clicking the **X** in the top right corner brings up a grid of images. Clicking an image on the grid returns to the single image viewer. \n\n",
    "supporting": [
      "app_files"
    ],
    "filters": [],
    "includes": {}
  }
}