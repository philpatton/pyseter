{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e3688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>melon_headed_whale</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>false_killer_whale</td>\n",
       "      <td>60008f293a2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4b00fe572063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>8e5253662392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image             species individual_id\n",
       "0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9\n",
       "1  000562241d384d.jpg      humpback_whale  1a71fbb72250\n",
       "2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b\n",
       "3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063\n",
       "4  00087baf5cef7a.jpg      humpback_whale  8e5253662392"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyseter.sort import load_features\n",
    "from pyseter.identify import identify\n",
    "from pyseter.review import launch_review\n",
    "import pandas as pd\n",
    "\n",
    "id_df = pd.read_csv('/Users/PattonP/datasets/happywhale/train.csv')\n",
    "\n",
    "reference_path = '/Users/PattonP/datasets/happywhale/features/train_features.npy'\n",
    "reference_files, reference_features = load_features(reference_path)\n",
    "\n",
    "query_path = '/Users/PattonP/datasets/happywhale/features/test_features.npy'\n",
    "query_files, query_features = load_features(query_path)\n",
    "\n",
    "query_dict = dict(zip(query_files, query_features))\n",
    "reference_dict = dict(zip(reference_files, reference_features))\n",
    "\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17e1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = identify(reference_dict, query_dict, id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.merge(score_df)\n",
    "\n",
    "# def evaluate_features(feature_dict, new_id_threshold=0.5, pred_count=5):\n",
    "\n",
    "#     train_feat = np.array([feature_dict[img] for img in train_images])\n",
    "#     test_feat = np.array([feature_dict[img] for img in test_images])\n",
    "        \n",
    "#     cosine_dist, index = knn_with_reference(train_feat, test_feat)\n",
    "#     preds = train_labels[index]\n",
    "    \n",
    "#     mod_preds, mod_score = insert_new_id(cosine_dist, preds, new_id_threshold)\n",
    "#     test_pred, test_score = pool_predictions(mod_preds, mod_score)\n",
    "\n",
    "#     # convert to string\n",
    "#     # strings = [' '.join(t[:5]) for t in test_pred]\n",
    "#     test_pred = [t[:5].tolist() for t in test_pred]\n",
    "\n",
    "#     precision = [map_per_image(l, p) for l, p in zip(test_labels, test_pred)]\n",
    "#     overall_score = np.mean(precision)\n",
    "\n",
    "#     # map_score = map_per_query(test_labels, test_pred)\n",
    "#     print(f\"MAP@{pred_count}: {overall_score:.3f}\")\n",
    "\n",
    "#     out_df = pd.DataFrame({\n",
    "#         \"image\": test_images,\n",
    "#         \"label\": test_labels,\n",
    "#         \"pred\": test_pred,\n",
    "#         \"score\": test_score,\n",
    "#         \"precision\": precision\n",
    "#     })\n",
    "\n",
    "#     return out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac75c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# from torchvision.io import decode_image\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# def visualize_bboxes(image_dir, bbox_csv, n=5):\n",
    "#     df = pd.read_csv(bbox_csv).sample(frac=1)\n",
    "#     fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
    "#     if n == 1: axes = [axes]\n",
    "    \n",
    "#     for ax, (_, row) in zip(axes, df.head(n).iterrows()):\n",
    "#         img = decode_image(os.path.join(image_dir, row['filename']))\n",
    "#         ax.imshow(img.permute(1, 2, 0))  # CHW -> HWC\n",
    "#         xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "#         rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "#                                   linewidth=2, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#         ax.set_title(row['filename'], fontsize=8)\n",
    "#         ax.axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('bbox_check.png', dpi=150)\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_bboxes(\n",
    "#     '/Users/PattonP/datasets/happywhale/train_images',\n",
    "#     '/Users/PattonP/datasets/happywhale/happywhale-charm-boxes.csv'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18873532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyseter.sort import load_features\n",
    "\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def find_neighbors(ref_feat, query_feat):\n",
    "#     neighborhood = NearestNeighbors(n_neighbors=500, metric=\"cosine\")\n",
    "#     neighborhood.fit(ref_feat)\n",
    "\n",
    "#     distances, indices = neighborhood.kneighbors(query_feat)\n",
    "#     return distances, indices\n",
    "\n",
    "# def insert_new_id(distances, predictions, threshold):\n",
    "\n",
    "#     # find position where we should slot new individual\n",
    "#     new_id_position = np.array(\n",
    "#         [np.searchsorted(s, threshold) for s in distances]\n",
    "#     )\n",
    "\n",
    "#     # insert \"new_individual\" into predictions and 0.5 into scores\n",
    "#     new_preds = [np.insert(t, i, 'new_individual') \n",
    "#                  for t, i in zip(predictions, new_id_position)]\n",
    "#     new_score = [1 - np.insert(t, i, 0.5) \n",
    "#                  for t, i in zip(distances, new_id_position)]\n",
    "\n",
    "#     return new_score, new_preds\n",
    "\n",
    "# def pool_predictions(predictions, scores):\n",
    "\n",
    "#     # find position of unique entry to eliminate redundant predictions \n",
    "#     unique_index = [np.unique(a, return_index=True)[1] for a in predictions]\n",
    "\n",
    "#     # convert index to string \n",
    "#     pooled_pred = [t[np.sort(i)] for t, i in zip(predictions, unique_index)]\n",
    "#     pooled_score = [t[np.sort(i)] for t, i in zip(scores, unique_index)]\n",
    "\n",
    "#     return pooled_score, pooled_pred\n",
    "\n",
    "# def map_per_image(label, predictions):\n",
    "#     \"\"\"Computes the precision score of one image.\"\"\"    \n",
    "#     try:\n",
    "#         return 1 / (predictions[:5].index(label) + 1)\n",
    "#     except ValueError:\n",
    "#         return 0.0\n",
    "    \n",
    "# def map_per_query(labels, predictions):\n",
    "#     \"\"\"Computes the precision score of all images.\"\"\"\n",
    "#     return np.mean([map_per_image(l, p) for l, p in zip(labels, predictions)])\n",
    "\n",
    "# def load_id_dict():\n",
    "#     map_path = '/Users/PattonP/datasets/happywhale/full_file_mapping2.csv'\n",
    "#     metadata = pd.read_csv(map_path)\n",
    "\n",
    "#     # stupid excel!\n",
    "#     metadata['temp_id'] = metadata['new_individual_id'].apply(\n",
    "#         lambda x: str(int(float(x))) if 'E+' in str(x) else x\n",
    "#     )\n",
    "\n",
    "#     train_data = metadata.loc[metadata[\"Usage\"] == \"Train\"]\n",
    "#     test_data = metadata.loc[metadata[\"Usage\"] != \"Train\"]\n",
    "\n",
    "#     reference_images = train_data[\"img_name_new\"].to_numpy()\n",
    "#     reference_ids = train_data[\"temp_id\"].to_numpy()\n",
    "\n",
    "#     query_images = test_data[\"img_name_new\"].to_numpy()\n",
    "#     query_ids = test_data[\"temp_id\"].to_numpy()\n",
    "\n",
    "#     id_dict = dict(zip(\n",
    "#         np.concatenate((reference_images, query_images)), \n",
    "#         np.concatenate((reference_ids, query_ids))\n",
    "#     ))\n",
    "\n",
    "#     return id_dict \n",
    "\n",
    "\n",
    "# # reference_path = '/Users/PattonP/datasets/happywhale/features/train_features.npy'\n",
    "# # reference_files, reference_features = load_features(reference_path)\n",
    "\n",
    "# # query_path = '/Users/PattonP/datasets/happywhale/features/test_features.npy'\n",
    "# # query_files, query_features = load_features(query_path)\n",
    "\n",
    "# # id_dict = load_id_dict()\n",
    "\n",
    "# # # takes about 19 seconds\n",
    "# # distance_matrix, index_matrix = find_neighbors(reference_features, query_features)\n",
    "\n",
    "# # # get the corresponding labels for each reference image\n",
    "# # nearest_files = reference_files[index_matrix]\n",
    "# # predicted_ids = np.vectorize(id_dict.get)(nearest_files).astype(str)\n",
    "\n",
    "# # # insert the prediction \"new_individual\" at the threshold\n",
    "# # distances, ids = insert_new_id(distance_matrix, predicted_ids, threshold=0.5)\n",
    "\n",
    "# # # remove redundant predictions and take the maximum \n",
    "# # pooled_distances, pooled_ids = pool_predictions(ids, distances)\n",
    "\n",
    "# # query_labels = np.vectorize(id_dict.get)(query_files).astype(str)\n",
    "\n",
    "# # final_predictions = [t[:5].tolist() for t in pooled_ids]\n",
    "# # map_per_query(query_labels, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv('/Users/PattonP/datasets/happywhale/train.csv')\n",
    "\n",
    "reference_path = '/Users/PattonP/datasets/happywhale/features/train_features.npy'\n",
    "reference_files, reference_features = load_features(reference_path)\n",
    "\n",
    "query_path = '/Users/PattonP/datasets/happywhale/features/test_features.npy'\n",
    "query_files, query_features = load_features(query_path)\n",
    "\n",
    "query_dict = dict(zip(query_files, query_features))\n",
    "reference_dict = dict(zip(reference_files, reference_features))\n",
    "# reference_dict_ids = dict(zip(reference_files, reference_features))\n",
    "\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769879d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack both dictionaries \n",
    "reference_files = np.array(list(reference_dict.keys()))\n",
    "reference_feats = np.array(list(reference_dict.values()))   \n",
    "\n",
    "query_files = np.array(list(query_dict.keys()))\n",
    "query_feats = np.array(list(query_dict.values()))  \n",
    "\n",
    "# this is the true id of every id in the reference dataset\n",
    "ids = id_df.set_index('image').loc[reference_files, 'individual_id'].values\n",
    "\n",
    "# takes about 19 seconds\n",
    "distance_matrix, index_matrix = find_neighbors(reference_feats, query_feats, )\n",
    "\n",
    "# get the corresponding labels for each reference image\n",
    "predicted_ids = ids[index_matrix]\n",
    "\n",
    "# # insert the prediction \"new_individual\" at the threshold\n",
    "# distances, ids = insert_new_id(distance_matrix, predicted_ids, threshold=0.5)\n",
    "\n",
    "# remove redundant predictions and take the maximum \n",
    "pooled_distances, pooled_ids = pool_predictions(predicted_ids, distance_matrix)\n",
    "\n",
    "final_predictions = [t[:10].tolist() for t in pooled_ids]\n",
    "final_distances = [t[:10].tolist() for t in pooled_distances]\n",
    "\n",
    "final_scores = 1 - np.array(final_distances)\n",
    "final_predictions = np.array(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds, scores = identify(reference_dict, query_dict, id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36aeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286df9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436128b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eba1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbbebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pyseter)",
   "language": "python",
   "name": "pyseter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
