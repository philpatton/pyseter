{"title":"R users who are new to Python","markdown":{"yaml":{"title":"R users who are new to Python"},"headingText":"Install conda","containsRefs":false,"markdown":"\n\nWe expect that most people using Pyseter will be familiar with R, and completely new to Python. This raises the question: why release Pyseter as a Python package? The answer is that Python is much more suited to deep learning than R, and most of the new developments in automated photo-identification rely on deep learning. \n\nAs such, Pyseter users will have to familiarize themselves with a few Python concepts, such as conda and Jupyter, before getting started. \n\n\nConda is an important tool for managing packages in Python. While R, for the most part, handles packages for you behind the scenes, Python requires a more hands on approach. \n\nTo get started, we first need to install a package manager called conda. There are many forms of conda, with Anaconda being the most popular. For several reasons, we prefer another form of conda called Miniforge.\n\n   - Download and install [Miniforge](https://conda-forge.org/download/) (a form of conda)\n\nAfter installing, you can verify your installation by opening the **command line interface** (CLI), which will depend on your operating system. Are you on Windows? Open the \"miniforge prompt\" in your start menu. Are you on Mac? Open the Terminal application. Then, type the following command into the CLI and hit return. \n\n```bash\nconda --version\n```\n\nYou should see something like `conda 25.5.1`. Of course, Anaconda, miniconda, mamba, or any other form of conda will work too.\n\n## Create a new environment\n\nThen, you'll create an environment for the package will live in. Environments are walled off areas where we can install packages. This allows you to have multiple versions of the same package installed on your machine, which can help prevent conflicts. \n\nEnter the following two commands into the CLI:\n\n``` bash\nconda create -n pyseter_env\nconda activate pyseter_env\n```\n\nHere, I name (hence the `-n`) the environment `pyseter_env`, but you can call it anything you like!\n\nNow your environment is ready to go! Try installing your first package, pip. Pip is another way of installing Python packages, and will be helpful for installing PyTorch and Pyseter (see below). To do so, enter the following command into the CLI.\n\n``` bash\nconda install pip -y\n```\n\nIn this case, we include the `-y` argument so we don't have to immediately answer `yes` to the next question. Once this is working, you're ready to proceed to the next section.\n\n## Install PyTorch\n\nInstalling PyTorch will allow users to extract features from images, i.e., identify individuals in images. Extracting features should be fast for users with an NVIDIA GPU, and reasonable for users with a Mac with Apple Silicon. \n\n:::{.callout-warning}\nFor all other users, extracting features from images will be extremely slow.\n:::\n\nPyTorch installation can be a little finicky. Essentially, it depends on what operating system you're using, and what version of **CUDA** you're using. CUDA is the technology that turns your NVIDIA GPU into a deep learning machine. To install PyTorch, I recommend following [these instructions](https://pytorch.org/get-started/locally/). \n\n### Windows users\n\nBelow is an example for Windows users. This relies on CUDA 12.8, which should work for most people. If you haven't already, open the CLI (e.g., the miniforge prompt). Then activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n```\nPyTorch is pretty big (over a gigabyte), so this may take a few minutes.\n\n### Mac users\n\nBelow is an example for Mac users. The Mac version of PyTorch relies on [MPS acceleration](https://docs.pytorch.org/docs/stable/notes/mps.html), which is good but not at the level of CUDA. If you haven't already, open you're command line interface (e.g., the miniforge prompt). Then activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install torch torchvision \n```\nPyTorch is pretty big (over a gigabyte), so this may take a few minutes.\n\n:::{.callout-warning}\nMac users will need to have an Apple Silicon processor, e.g., an M1 chip. Additionally, they will need at least 16 GB of memory (RAM) to use AnyDorsal.\n:::\n\n### Linux users\n\nYou run Linux, but you've never used Python?\n\n## Install Pyseter\n\nNow, install Pyseter. If you haven't already, activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install pyseter\n```\n\nNow you're ready to go! \n\n## Install VS Code or Positron\n\nMost users will interact with Pyseter via a Jupyter Notebook. There are many methods for opening, editing, running, and saving Jupyter Notebooks. We are personally biased towards VS Code. Alternatively, R users might also try out [Positron](https://positron.posit.co). The team at Posit (formerly, R Studio) developed Positron from the open source version of VS Code, but with R users in mind. As such, it might be a nice hybrid option. That said, we have found Positron to throw confusing errors and have found VS Code to be more stable. \n\n- Download and install [VS Code](https://code.visualstudio.com/download) \n\nOpen VS Code, then click \"File -> Open Folder\". Navigate to wherever you'd like to work, then click \"New Folder.\" You can call this folder something like \"learn-pyseter\" or \"pyseter-jobs\". Open the new folder. Click \"File -> New File\" then select Jupyter Notebook. Click \"Select Kernel\" in the top right corner, select \"Python environments\" and then \"pyseter_env\", or whatever you named your environment. For more information, check out [this great overview](https://code.visualstudio.com/docs/datascience/jupyter-notebooks) of using Jupyter Notebooks in VS Code. \n\nNow you're ready to proceed to the next section. \n\n## Verify the installation\n\nVerify the Pyseter installation by running the following cell in your notebook.\n\n``` python\nimport pyseter\npyseter.verify_pytorch()\n```\n\nIf you're on a windows computer with an NVIDIA GPU, you should see something like\n\n```\n✓ PyTorch 2.7.1+cu126 detected\n✓ CUDA GPU available: NVIDIA A30 MIG 2g.12gb\n```\n\nOnce this is working, you're ready to check out the \"General Overview\" [notebook](https://github.com/philpatton/pyseter/blob/main/examples/general-overview.ipynb) in the examples folder of this repository! \n\n## AnyDorsal weights\n\nPyseter relies on the [AnyDorsal algorithm](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14167) to extract features from images. The first time you use the `FeatureExtractor`, Pyseter will download the AnyDorsal weights from Hugging Face. The weights take up roughly 4.5 GB. As such, to use the `FeatureExtractor`, users must have enough storage space to accommodate the weights. \n","srcMarkdownNoYaml":"\n\nWe expect that most people using Pyseter will be familiar with R, and completely new to Python. This raises the question: why release Pyseter as a Python package? The answer is that Python is much more suited to deep learning than R, and most of the new developments in automated photo-identification rely on deep learning. \n\nAs such, Pyseter users will have to familiarize themselves with a few Python concepts, such as conda and Jupyter, before getting started. \n\n## Install conda \n\nConda is an important tool for managing packages in Python. While R, for the most part, handles packages for you behind the scenes, Python requires a more hands on approach. \n\nTo get started, we first need to install a package manager called conda. There are many forms of conda, with Anaconda being the most popular. For several reasons, we prefer another form of conda called Miniforge.\n\n   - Download and install [Miniforge](https://conda-forge.org/download/) (a form of conda)\n\nAfter installing, you can verify your installation by opening the **command line interface** (CLI), which will depend on your operating system. Are you on Windows? Open the \"miniforge prompt\" in your start menu. Are you on Mac? Open the Terminal application. Then, type the following command into the CLI and hit return. \n\n```bash\nconda --version\n```\n\nYou should see something like `conda 25.5.1`. Of course, Anaconda, miniconda, mamba, or any other form of conda will work too.\n\n## Create a new environment\n\nThen, you'll create an environment for the package will live in. Environments are walled off areas where we can install packages. This allows you to have multiple versions of the same package installed on your machine, which can help prevent conflicts. \n\nEnter the following two commands into the CLI:\n\n``` bash\nconda create -n pyseter_env\nconda activate pyseter_env\n```\n\nHere, I name (hence the `-n`) the environment `pyseter_env`, but you can call it anything you like!\n\nNow your environment is ready to go! Try installing your first package, pip. Pip is another way of installing Python packages, and will be helpful for installing PyTorch and Pyseter (see below). To do so, enter the following command into the CLI.\n\n``` bash\nconda install pip -y\n```\n\nIn this case, we include the `-y` argument so we don't have to immediately answer `yes` to the next question. Once this is working, you're ready to proceed to the next section.\n\n## Install PyTorch\n\nInstalling PyTorch will allow users to extract features from images, i.e., identify individuals in images. Extracting features should be fast for users with an NVIDIA GPU, and reasonable for users with a Mac with Apple Silicon. \n\n:::{.callout-warning}\nFor all other users, extracting features from images will be extremely slow.\n:::\n\nPyTorch installation can be a little finicky. Essentially, it depends on what operating system you're using, and what version of **CUDA** you're using. CUDA is the technology that turns your NVIDIA GPU into a deep learning machine. To install PyTorch, I recommend following [these instructions](https://pytorch.org/get-started/locally/). \n\n### Windows users\n\nBelow is an example for Windows users. This relies on CUDA 12.8, which should work for most people. If you haven't already, open the CLI (e.g., the miniforge prompt). Then activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n```\nPyTorch is pretty big (over a gigabyte), so this may take a few minutes.\n\n### Mac users\n\nBelow is an example for Mac users. The Mac version of PyTorch relies on [MPS acceleration](https://docs.pytorch.org/docs/stable/notes/mps.html), which is good but not at the level of CUDA. If you haven't already, open you're command line interface (e.g., the miniforge prompt). Then activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install torch torchvision \n```\nPyTorch is pretty big (over a gigabyte), so this may take a few minutes.\n\n:::{.callout-warning}\nMac users will need to have an Apple Silicon processor, e.g., an M1 chip. Additionally, they will need at least 16 GB of memory (RAM) to use AnyDorsal.\n:::\n\n### Linux users\n\nYou run Linux, but you've never used Python?\n\n## Install Pyseter\n\nNow, install Pyseter. If you haven't already, activate your environment before installing.\n\n``` bash\nconda activate pyseter_env\npip3 install pyseter\n```\n\nNow you're ready to go! \n\n## Install VS Code or Positron\n\nMost users will interact with Pyseter via a Jupyter Notebook. There are many methods for opening, editing, running, and saving Jupyter Notebooks. We are personally biased towards VS Code. Alternatively, R users might also try out [Positron](https://positron.posit.co). The team at Posit (formerly, R Studio) developed Positron from the open source version of VS Code, but with R users in mind. As such, it might be a nice hybrid option. That said, we have found Positron to throw confusing errors and have found VS Code to be more stable. \n\n- Download and install [VS Code](https://code.visualstudio.com/download) \n\nOpen VS Code, then click \"File -> Open Folder\". Navigate to wherever you'd like to work, then click \"New Folder.\" You can call this folder something like \"learn-pyseter\" or \"pyseter-jobs\". Open the new folder. Click \"File -> New File\" then select Jupyter Notebook. Click \"Select Kernel\" in the top right corner, select \"Python environments\" and then \"pyseter_env\", or whatever you named your environment. For more information, check out [this great overview](https://code.visualstudio.com/docs/datascience/jupyter-notebooks) of using Jupyter Notebooks in VS Code. \n\nNow you're ready to proceed to the next section. \n\n## Verify the installation\n\nVerify the Pyseter installation by running the following cell in your notebook.\n\n``` python\nimport pyseter\npyseter.verify_pytorch()\n```\n\nIf you're on a windows computer with an NVIDIA GPU, you should see something like\n\n```\n✓ PyTorch 2.7.1+cu126 detected\n✓ CUDA GPU available: NVIDIA A30 MIG 2g.12gb\n```\n\nOnce this is working, you're ready to check out the \"General Overview\" [notebook](https://github.com/philpatton/pyseter/blob/main/examples/general-overview.ipynb) in the examples folder of this repository! \n\n## AnyDorsal weights\n\nPyseter relies on the [AnyDorsal algorithm](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14167) to extract features from images. The first time you use the `FeatureExtractor`, Pyseter will download the AnyDorsal weights from Hugging Face. The weights take up roughly 4.5 GB. As such, to use the `FeatureExtractor`, users must have enough storage space to accommodate the weights. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"install-r.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.25","quartodoc":{"style":"pkgdown","dir":"api","package":"pyseter","title":"API Reference","sections":[{"title":"Feature Extraction","desc":"Extracting feature vectors from images","contents":["extract.FeatureExtractor"]},{"title":"Sorting and Clustering","desc":"Clustering images by proposed IDs","contents":["sort.HierarchicalCluster","sort.NetworkCluster","sort.ClusterResults","sort.prep_images","sort.sort_images","sort.load_features"]},{"title":"Grading","desc":"Grade images by distinctiveness","contents":["grade.rate_distinctiveness"]},{"title":"Verifying Installation","desc":"Functions to make sure PyTorch is working","contents":["get_best_device","verify_pytorch"]}]},"theme":{"light":"flatly","dark":"darkly"},"code-copy":true,"title":"R users who are new to Python"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}