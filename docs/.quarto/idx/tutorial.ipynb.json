{"title":"Introduction to pyseter","markdown":{"yaml":{"title":"Introduction to pyseter","jupyter":{"kernelspec":{"display_name":"Python (pyseter)","language":"python","name":"pyseter"}}},"headingText":"R user tip","containsRefs":false,"markdown":"\n\nPyseter is an Python package for sorting images by an automatically generated ID. The main functions of Pyseter are:\n\n1. Extracting features from images\n2. Clustering images by proposed ID\n3. Sorting images by cluster\n4. Grading images by distinctiveness\n\nThis notebook will walk you through each major function. First, let's make sure that Pyseter is properly installed, and that it can access Pytorch.  \n\nIf you're on a Mac, you should see something like\n\n```bash\n✓ PyTorch 2.7.0 detected\n✓ Apple Silicon (MPS) GPU available\n```\n\nPlease note, however, that AnyDorsal consumes quite a bit of memory. As such, only Apple Silicon devices with 16 GB or more of memory will work. Ideally, future versions of Pyseter will use a smaller model.\n\nIf neither Apple Silicon or an NVIDIA GPU are available, you will see a message like this.\n\n```bash\n✓ PyTorch 2.7.1+cu126 detected\n! No GPU acceleration available. Expect slow feature extraction.\n```\n\nPackages in Python tend to be subdivided into modules based on their functions. In Pyseter, the `sort` module contains functions for sorting files, including other forms of file management. \n\n:::{.callout-tip}\n\nIn R, the above code block would look something like\n\n```\nlibrary(pyseter)\nverify_pytorch()\n```\n\nor, \n\n```\npyseter::verify_pytorch()\n```\n\nImports work a little differently in Python. First, we need tell Python that this package is available for imports, `import pyseter`, then we need to explicitly call the function from the library `pyseter.verify_pytorch()`. To an R user, this can feel overly wordy. Nevertheless, this wordiness helps keep the global environment clean. Whereas R sessions frequently have to deal with [masking names](https://adv-r.hadley.nz/functions.html?q=masking#lexical-scoping), this rarely happens in Python. \n:::\n\n## Optional: Folder management\n\nThe main purpose of Pyseter is organizing images into folders. To do keep things clean and tidy, we recommend establishing a `working directory` with a subfolder, e.g., called, `all images`, that contains every image you want to be sorted (see below for a different case). Optionally, you might want to have a .csv with encounter information in the working directory. This .csv would contain two columns: one for the image name, i.e., every image in `all images`, and another for the encounter. As such, the working directory would look like this. \n\n```bash\nworking directory\n├── encounter_info.csv\n├── all images\n│   └──00cef32dc62b0f.jpg\n│   └──3ecc025ea6f9bf.jpg\n│   └──9f18762a48696b.jpg\n│   └──36f78517a512dd.jpg\n│   └──470d524b4d5303.jpg\n       ...\n│   └──4511c9e5cb7acb.jpg\n```\n\nSometimes, you might have your images organized into subfolders by encounter. \n\n```bash\nworking_dir\n└── original_images\n    ├── SL_HI_006_20220616 (CROPPED)\n    │   ├── 2022-06-16_CLD500_CL_006.JPG\n    │   ├── 2022-06-16_CLD500_CL_007.JPG\n    │   ├── 2022-06-16_CLD500_CL_008.JPG\n    │   ├── 2022-06-16_CLD500_CL_021.JPG\n    │   ├── 2022-06-16_CLD500_CL_042.JPG\n...\n    ├── SL_HI_007_20220616 (CROPPED)\n    │   ├── 2022-06-16_CLD500_CL_346.JPG\n    │   ├── 2022-06-16_CLD500_CL_347.JPG\n    │   ├── 2022-06-16_CLD500_CL_371.JPG\n    │   ├── 2022-06-16_CLD500_CL_372.JPG\n```\n\nIn this case, you might want to accomplish two tasks: move all these images to one folder, e.g., `all_images`, and create a .csv that indicates which image belongs to which encounter (i.e., a map from image to encounter). The `prep_images()` function does just that. \n\n::: {.callout-tip}\n## R user tip\n\nIn python, you can concatenate strings with the `+` operator. This is equivalent to `paste0(working_dir, '/original_images')` in R. \n:::\n\n::: {.callout-tip}\n## R user tip\n\nPackages in Python tend to be subdivided into modules based on their functions. In Pyseter, the `sort` module contains functions for sorting files, including other forms of file management. \n:::\n\n## 1. Extracting features\n\nPyseter identifies individuals by extracting *feature vectors* from images. Feature vectors summarize three-dimensional images into one-dimensional vectors that are useful for the task at hand, in this case, individual identification. \n\nPyseter extracts feature vectors with [AnyDorsal](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14167), an algorithm for identifying whales and dolphins of many species. AnyDorsal is the same dorsal identification algorithm that's included with [Happywhale](https://happywhale.com/home) (although not to be confused with their humpback whale fluke ID algorithm). \n\nBefore we extract the feature vectors, let's first create a subfolder within our working directory to save them in. This isn't necessary, yet keeps things tidy. \n\n\n::: {.callout-tip}\n## R user tip \nThe module, `os`,  is part of Python's *standard library*. People often refer to R and its standard libraries as \"base R.\" Base R includes the stats library, which provides the function `rnorm`. The `os` module has many functions for tinkering with your operating system. \n:::\n\nWe will extract features with the `FeatureExtractor` class. To do so, we first need to initialize the class. This sets up important parameters, such as the `batch_size`, which is the number of images that will be processed in parallel. Larger batches should run faster, although your mileage may vary. If you specify too large of a batch, you may encounter an `OutOfMemoryError` (see below for an example). If you encounter this error, try specifying a larger batch size. If you encounter this error with a very small batch size (say, 2), you may need to resize your images. You can do this manually by reducing the file size in an image editing software, or [with Python](https://imagekit.io/blog/image-resizing-in-python/)\n\n<pre style=\"white-space: pre-wrap; word-wrap: break-word;\">\nOutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 5.81 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 5.76 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 50.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n</pre>\n\n:::{.callout-tip}\n## R user tip\nPython error messages are comically long, putting CVS receipts to shame. This is because they show the entire traceback, i.e., this error caused this error caused this error, etc. To quickly diagnose the problem, scroll to the bottom of the message. Then, you can further dissect it by scrolling up.\n:::\n\n\nOnce we've initialize the class, we can use its associated methods (functions). In this case, the only one we are interested in is `extract()`, which extracts a feature vector for every image in a specified directory. This can take several minutes, so we typically save the results afterwards. \n \n:::{.callout-tip}\n## R user tip\nClasses and methods also exist in R, but operate more behind the scenes. For example, `x <- data.frame()` initializes an object of class data.frame, and `summary(x)` calls the summary method for data.frames. Python makes this relationship more explicit. For example, the equivalent (although nonsensical) Python code would be `x = data.frame()` and `x.summary()`. \n:::\n\nThe object `features` is a dictionary, whose keys are the filenames and whose values are the feature vectors associated with each filename. This helps ensure that each image is associated with the correct feature vector. Nevertheless, it can be easier to work with actual numpy arrays. To do so, convert the keys to a list, then to a numpy array.\n\n:::{.callout-tip}\n## R user tip\nThe R objects that Python's dictionary most resemble is the [named vector](https://adv-r.hadley.nz/vectors-chap.html?q=named%20vector#attr-names) or the [list](https://adv-r.hadley.nz/vectors-chap.html?q=named%20vector#lists). Like a list, dictionaries can hold different data types. Unlike a list, dictionaries have no order, and therefore cannot be integer indexed.\n:::\n\nIf you've already extracted and saved features, you can load them with the code below.\n\n## 2. Clustering images by proposed ID\n\nPyseter comes with two algorithm's for clustering images by proposed ID. Network clustering works better for small datasets. To use network clustering, we first need to compute the similarity scores between each pair of images.\n\nThis indicates how similar the individuals in each image are. \n\nNext, we can perform the clustering. Each cluster represents a proposed ID. To access the \"cluster labels\" (these are just integers representing the cluster), we can access the cluster_idx attribute, i.e, `results.cluster_idx`. \n\nNetwork clustering has one major hyperparameter, namely, the `match_threshold`, which indicates whether two images should be grouped within a cluster. That is, if the similarity score between two images is above a certain threshold, we cluster them into a proposed ID. High thresholds mean that few images will be clustered together, creating many clusters. Very low thresholds mean that many images will be clustered together, creating few clusters. `report_cluster_results` produces a quick and dirty summary of the number of clusters created, and the size of the largest cluster (i.e., the number of images associated to the most photographed individual). This is a quick sanity check.\n\nYou'll also note that `nc.cluster_images()` warns that some clusters may contain \"false positives.\" False positive matches occur when two separate individuals fall under the same proposed ID. We can diagnose possible false positives by evaluating the network. In this case, the network consists of nodes (images) and edges, which represent connections between images. Two images are connected when they have a similarity score above the threshold. A blob of connected nodes (i.e., connected components) represents a proposed ID. \n\nSometimes, the connected components look less like a blob and more like a barbell, where two sets of images have many connections amongst each other, yet these two blobs are only connected by one link. We suspect that such clusters contain false positives, i.e., two sets of images for two individuals connected by one spurious link. We can plot the networks of the suspicious clusters with `results.plot_suspicious()`.\n\n`ID_0033` clearly has a barbell shape, suggesting that this cluster consists of images for two individuals linked together by one spurious connection.`ID_0013` also seems dubious, and `ID_0060` might consist of four separate individuals. \n\nUsers can deal with suspicious clusters in several ways. First, raising the match threshold should reduce the number of false positive matches. That said, this will increase the *false negative rate*, whereby images of one individual are spread across multiple proposed IDs. Alternatively, users can manually inspect the images within the clusters and, if need be, divide up the images. \n\nAs the number of images being clustered grows, the overall false positive rate also grows (this is analogous the [multiple comparison problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem) in statistics). At some point,the network matching becomes untenable; all but the highest match thresholds would produce too many false positives to be useful.\n\nFor these cases, there is `HierarchicalCluster`, which relies on the [Hierarchical Agglomerative Clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering) algorithm provided by the popular machine learning package, scikit-learn. Note that `HierarchicalCluster` will run noticeably slower than the `NetworkCluster`.\n\nThe `HierarchicalCluster` results object is much simpler, in that it just returns the cluster indices for each image. We can make these labels a little prettier with the `format_ids` function. \n\n`HierarchicalCluster` is useful for large datasets, yet will be more prone to false negative errors. In this example, it found 60 more clusters (proposed IDs) than the network matching, which may be dubious. Users will have to decide for themselves how to balance false positive versus false negative matches. For example, we recommend that users preprocess their images with Pyseter, then identify animals in the pre-processed images manually or with Happywhale. This second round of identification should help clean up false negative matches. As such, users following this approach might be more averse to false positive errors in the first stage. \n\n## 3. Sorting images by proposed ID\n\nOnce we've identified individuals, we can sort them into folder by proposed ID and encounter. To do so, we need to create a pandas `DataFrame` that indicates the proposed ID and encounter for each filename. Recall that we created the `encounter_info.csv` with the `prep_images()` function above. For this sort, we'll use the NetworkCluster results\n\n::: {.callout-warning}\n## Formatting the ID DataFrame\nThe ID DataFrame must have columns named image, proposed_id, and encounter. Otherwise sort_images will not work. Luckily, changing column names in pandas is straightforward.\n\n```python\nnetwork_df.columns = ['image', 'proposed_id', 'encounter']\n```\n:::\n\n:::{.callout-tip}\n## R user tip\nPandas is a package for managing dataframes, and is a straight knock-off of R's data.frame. In my experience, most R users lose patience not with Python, but with pandas. Pandas is *just* similar enough to R that one should be able to directly port R ideas over. However, key differences between pandas and R prevent this, causing immense frustration (especially for yours truly!)\n:::\n\nTo sort the images, we need to specify an output directory, then run the `sort_images` function.  \n\nWe can check to see that this worked by plotting a grid of images with matplotlib.\n","srcMarkdownNoYaml":"\n\nPyseter is an Python package for sorting images by an automatically generated ID. The main functions of Pyseter are:\n\n1. Extracting features from images\n2. Clustering images by proposed ID\n3. Sorting images by cluster\n4. Grading images by distinctiveness\n\nThis notebook will walk you through each major function. First, let's make sure that Pyseter is properly installed, and that it can access Pytorch.  \n\nIf you're on a Mac, you should see something like\n\n```bash\n✓ PyTorch 2.7.0 detected\n✓ Apple Silicon (MPS) GPU available\n```\n\nPlease note, however, that AnyDorsal consumes quite a bit of memory. As such, only Apple Silicon devices with 16 GB or more of memory will work. Ideally, future versions of Pyseter will use a smaller model.\n\nIf neither Apple Silicon or an NVIDIA GPU are available, you will see a message like this.\n\n```bash\n✓ PyTorch 2.7.1+cu126 detected\n! No GPU acceleration available. Expect slow feature extraction.\n```\n\nPackages in Python tend to be subdivided into modules based on their functions. In Pyseter, the `sort` module contains functions for sorting files, including other forms of file management. \n\n:::{.callout-tip}\n## R user tip\n\nIn R, the above code block would look something like\n\n```\nlibrary(pyseter)\nverify_pytorch()\n```\n\nor, \n\n```\npyseter::verify_pytorch()\n```\n\nImports work a little differently in Python. First, we need tell Python that this package is available for imports, `import pyseter`, then we need to explicitly call the function from the library `pyseter.verify_pytorch()`. To an R user, this can feel overly wordy. Nevertheless, this wordiness helps keep the global environment clean. Whereas R sessions frequently have to deal with [masking names](https://adv-r.hadley.nz/functions.html?q=masking#lexical-scoping), this rarely happens in Python. \n:::\n\n## Optional: Folder management\n\nThe main purpose of Pyseter is organizing images into folders. To do keep things clean and tidy, we recommend establishing a `working directory` with a subfolder, e.g., called, `all images`, that contains every image you want to be sorted (see below for a different case). Optionally, you might want to have a .csv with encounter information in the working directory. This .csv would contain two columns: one for the image name, i.e., every image in `all images`, and another for the encounter. As such, the working directory would look like this. \n\n```bash\nworking directory\n├── encounter_info.csv\n├── all images\n│   └──00cef32dc62b0f.jpg\n│   └──3ecc025ea6f9bf.jpg\n│   └──9f18762a48696b.jpg\n│   └──36f78517a512dd.jpg\n│   └──470d524b4d5303.jpg\n       ...\n│   └──4511c9e5cb7acb.jpg\n```\n\nSometimes, you might have your images organized into subfolders by encounter. \n\n```bash\nworking_dir\n└── original_images\n    ├── SL_HI_006_20220616 (CROPPED)\n    │   ├── 2022-06-16_CLD500_CL_006.JPG\n    │   ├── 2022-06-16_CLD500_CL_007.JPG\n    │   ├── 2022-06-16_CLD500_CL_008.JPG\n    │   ├── 2022-06-16_CLD500_CL_021.JPG\n    │   ├── 2022-06-16_CLD500_CL_042.JPG\n...\n    ├── SL_HI_007_20220616 (CROPPED)\n    │   ├── 2022-06-16_CLD500_CL_346.JPG\n    │   ├── 2022-06-16_CLD500_CL_347.JPG\n    │   ├── 2022-06-16_CLD500_CL_371.JPG\n    │   ├── 2022-06-16_CLD500_CL_372.JPG\n```\n\nIn this case, you might want to accomplish two tasks: move all these images to one folder, e.g., `all_images`, and create a .csv that indicates which image belongs to which encounter (i.e., a map from image to encounter). The `prep_images()` function does just that. \n\n::: {.callout-tip}\n## R user tip\n\nIn python, you can concatenate strings with the `+` operator. This is equivalent to `paste0(working_dir, '/original_images')` in R. \n:::\n\n::: {.callout-tip}\n## R user tip\n\nPackages in Python tend to be subdivided into modules based on their functions. In Pyseter, the `sort` module contains functions for sorting files, including other forms of file management. \n:::\n\n## 1. Extracting features\n\nPyseter identifies individuals by extracting *feature vectors* from images. Feature vectors summarize three-dimensional images into one-dimensional vectors that are useful for the task at hand, in this case, individual identification. \n\nPyseter extracts feature vectors with [AnyDorsal](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14167), an algorithm for identifying whales and dolphins of many species. AnyDorsal is the same dorsal identification algorithm that's included with [Happywhale](https://happywhale.com/home) (although not to be confused with their humpback whale fluke ID algorithm). \n\nBefore we extract the feature vectors, let's first create a subfolder within our working directory to save them in. This isn't necessary, yet keeps things tidy. \n\n\n::: {.callout-tip}\n## R user tip \nThe module, `os`,  is part of Python's *standard library*. People often refer to R and its standard libraries as \"base R.\" Base R includes the stats library, which provides the function `rnorm`. The `os` module has many functions for tinkering with your operating system. \n:::\n\nWe will extract features with the `FeatureExtractor` class. To do so, we first need to initialize the class. This sets up important parameters, such as the `batch_size`, which is the number of images that will be processed in parallel. Larger batches should run faster, although your mileage may vary. If you specify too large of a batch, you may encounter an `OutOfMemoryError` (see below for an example). If you encounter this error, try specifying a larger batch size. If you encounter this error with a very small batch size (say, 2), you may need to resize your images. You can do this manually by reducing the file size in an image editing software, or [with Python](https://imagekit.io/blog/image-resizing-in-python/)\n\n<pre style=\"white-space: pre-wrap; word-wrap: break-word;\">\nOutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 5.81 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 5.76 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 50.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n</pre>\n\n:::{.callout-tip}\n## R user tip\nPython error messages are comically long, putting CVS receipts to shame. This is because they show the entire traceback, i.e., this error caused this error caused this error, etc. To quickly diagnose the problem, scroll to the bottom of the message. Then, you can further dissect it by scrolling up.\n:::\n\n\nOnce we've initialize the class, we can use its associated methods (functions). In this case, the only one we are interested in is `extract()`, which extracts a feature vector for every image in a specified directory. This can take several minutes, so we typically save the results afterwards. \n \n:::{.callout-tip}\n## R user tip\nClasses and methods also exist in R, but operate more behind the scenes. For example, `x <- data.frame()` initializes an object of class data.frame, and `summary(x)` calls the summary method for data.frames. Python makes this relationship more explicit. For example, the equivalent (although nonsensical) Python code would be `x = data.frame()` and `x.summary()`. \n:::\n\nThe object `features` is a dictionary, whose keys are the filenames and whose values are the feature vectors associated with each filename. This helps ensure that each image is associated with the correct feature vector. Nevertheless, it can be easier to work with actual numpy arrays. To do so, convert the keys to a list, then to a numpy array.\n\n:::{.callout-tip}\n## R user tip\nThe R objects that Python's dictionary most resemble is the [named vector](https://adv-r.hadley.nz/vectors-chap.html?q=named%20vector#attr-names) or the [list](https://adv-r.hadley.nz/vectors-chap.html?q=named%20vector#lists). Like a list, dictionaries can hold different data types. Unlike a list, dictionaries have no order, and therefore cannot be integer indexed.\n:::\n\nIf you've already extracted and saved features, you can load them with the code below.\n\n## 2. Clustering images by proposed ID\n\nPyseter comes with two algorithm's for clustering images by proposed ID. Network clustering works better for small datasets. To use network clustering, we first need to compute the similarity scores between each pair of images.\n\nThis indicates how similar the individuals in each image are. \n\nNext, we can perform the clustering. Each cluster represents a proposed ID. To access the \"cluster labels\" (these are just integers representing the cluster), we can access the cluster_idx attribute, i.e, `results.cluster_idx`. \n\nNetwork clustering has one major hyperparameter, namely, the `match_threshold`, which indicates whether two images should be grouped within a cluster. That is, if the similarity score between two images is above a certain threshold, we cluster them into a proposed ID. High thresholds mean that few images will be clustered together, creating many clusters. Very low thresholds mean that many images will be clustered together, creating few clusters. `report_cluster_results` produces a quick and dirty summary of the number of clusters created, and the size of the largest cluster (i.e., the number of images associated to the most photographed individual). This is a quick sanity check.\n\nYou'll also note that `nc.cluster_images()` warns that some clusters may contain \"false positives.\" False positive matches occur when two separate individuals fall under the same proposed ID. We can diagnose possible false positives by evaluating the network. In this case, the network consists of nodes (images) and edges, which represent connections between images. Two images are connected when they have a similarity score above the threshold. A blob of connected nodes (i.e., connected components) represents a proposed ID. \n\nSometimes, the connected components look less like a blob and more like a barbell, where two sets of images have many connections amongst each other, yet these two blobs are only connected by one link. We suspect that such clusters contain false positives, i.e., two sets of images for two individuals connected by one spurious link. We can plot the networks of the suspicious clusters with `results.plot_suspicious()`.\n\n`ID_0033` clearly has a barbell shape, suggesting that this cluster consists of images for two individuals linked together by one spurious connection.`ID_0013` also seems dubious, and `ID_0060` might consist of four separate individuals. \n\nUsers can deal with suspicious clusters in several ways. First, raising the match threshold should reduce the number of false positive matches. That said, this will increase the *false negative rate*, whereby images of one individual are spread across multiple proposed IDs. Alternatively, users can manually inspect the images within the clusters and, if need be, divide up the images. \n\nAs the number of images being clustered grows, the overall false positive rate also grows (this is analogous the [multiple comparison problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem) in statistics). At some point,the network matching becomes untenable; all but the highest match thresholds would produce too many false positives to be useful.\n\nFor these cases, there is `HierarchicalCluster`, which relies on the [Hierarchical Agglomerative Clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering) algorithm provided by the popular machine learning package, scikit-learn. Note that `HierarchicalCluster` will run noticeably slower than the `NetworkCluster`.\n\nThe `HierarchicalCluster` results object is much simpler, in that it just returns the cluster indices for each image. We can make these labels a little prettier with the `format_ids` function. \n\n`HierarchicalCluster` is useful for large datasets, yet will be more prone to false negative errors. In this example, it found 60 more clusters (proposed IDs) than the network matching, which may be dubious. Users will have to decide for themselves how to balance false positive versus false negative matches. For example, we recommend that users preprocess their images with Pyseter, then identify animals in the pre-processed images manually or with Happywhale. This second round of identification should help clean up false negative matches. As such, users following this approach might be more averse to false positive errors in the first stage. \n\n## 3. Sorting images by proposed ID\n\nOnce we've identified individuals, we can sort them into folder by proposed ID and encounter. To do so, we need to create a pandas `DataFrame` that indicates the proposed ID and encounter for each filename. Recall that we created the `encounter_info.csv` with the `prep_images()` function above. For this sort, we'll use the NetworkCluster results\n\n::: {.callout-warning}\n## Formatting the ID DataFrame\nThe ID DataFrame must have columns named image, proposed_id, and encounter. Otherwise sort_images will not work. Luckily, changing column names in pandas is straightforward.\n\n```python\nnetwork_df.columns = ['image', 'proposed_id', 'encounter']\n```\n:::\n\n:::{.callout-tip}\n## R user tip\nPandas is a package for managing dataframes, and is a straight knock-off of R's data.frame. In my experience, most R users lose patience not with Python, but with pandas. Pandas is *just* similar enough to R that one should be able to directly port R ideas over. However, key differences between pandas and R prevent this, causing immense frustration (especially for yours truly!)\n:::\n\nTo sort the images, we need to specify an output directory, then run the `sort_images` function.  \n\nWe can check to see that this worked by plotting a grid of images with matplotlib.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"tutorial.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.25","quartodoc":{"style":"pkgdown","dir":"api","package":"pyseter","title":"API Reference","sections":[{"title":"Feature Extraction","desc":"Extracting feature vectors from images","contents":["extract.FeatureExtractor"]},{"title":"Sorting and Clustering","desc":"Clustering images by proposed IDs","contents":["sort.HierarchicalCluster","sort.NetworkCluster","sort.prep_images","sort.sort_images","sort.load_features"]},{"title":"Grading","desc":"Grade images by distinctiveness","contents":["grade.rate_distinctiveness"]},{"title":"Verifying Installation","desc":"Functions to make sure PyTorch is working","contents":["get_best_device","verify_pytorch"]}]},"theme":{"light":"flatly","dark":"darkly"},"code-copy":true,"title":"Introduction to pyseter","jupyter":{"kernelspec":{"display_name":"Python (pyseter)","language":"python","name":"pyseter"}}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}