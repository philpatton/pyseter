{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Computing false negative rates\n",
        "bibliography: references.bib\n",
        "jupyter:\n",
        "  kernelspec:\n",
        "    display_name: Python (Pyseter)\n",
        "    language: python\n",
        "    name: pyseter_env\n",
        "execute:\n",
        "  cache: true\n",
        "---\n",
        "\n",
        "A subtle but important choice when deciding how to automate photo-ID is the number of proposed matches you are going to evaluate before deciding that an individual is new to the dataset. An algorithm optimist might argue that you just need to check the first proposed ID to make sure it's not a false positive (i.e., claiming two distinct individuals are one). An algorithm skeptic might argue that you need to check every proposed ID, i.e., every individual in the reference set, before adding a new individual to the dataset.\n",
        "\n",
        "We can reframe this debate in terms of false negative rates. A false negative occurs when you didn't look far enough down the list of proposed IDs, and added a new individual that already existed in the dataset. Our algorithm optimist is arguing that the algorithm won't produce false negatives, or they aren't important. Our algorithm skeptic is arguing that the algorithm will produce false negatives and that false negatives are critical.\n",
        "\n",
        "The skeptic is right in that false negatives are critically important. An 8% false negative rate might seem small, but it suggests that you will overestimate your population size by 20% [@patton-2025-optimizing]. This overestimation can have grim consequences if, say, the estimate is used to compute potential biological removal.\n",
        "\n",
        "Either the skeptic or the optimist could be right about the prevalence of false negatives. But why trust them, when we can estimate them ourselves?\n",
        "\n",
        "## Dataset\n",
        "\n",
        "To demonstrate how to compute false negative rates, we'll use the [Happy Whale and Dolphin Kaggle competition dataset](https://www.kaggle.com/competitions/happy-whale-and-dolphin/data) as an example. You can download the data by following that linked page (click the big \"Download all\" button). FYI, you'll have to create an account first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyseter.sort import load_features\n",
        "from pyseter.identify import predict_ids\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def where(list, value):\n",
        "    \"\"\"Where in the list is the \"\"\"\n",
        "    try:\n",
        "        return (list.index(value) + 1)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "# load in the feature vectors\n",
        "data_dir = '/Users/PattonP/datasets/happywhale/'\n",
        "feature_dir = data_dir + '/features'\n",
        "\n",
        "reference_path = feature_dir + '/train_features.npy'\n",
        "reference_files, reference_features = load_features(reference_path)\n",
        "\n",
        "query_path = feature_dir + '/test_features.npy'\n",
        "query_files, query_features = load_features(query_path)\n",
        "\n",
        "# get the IDs for every individual in the happywhale set\n",
        "data_url = (\n",
        "    'https://raw.githubusercontent.com/philpatton/pyseter/main/' \n",
        "    'data/happywhale-ids.csv'\n",
        ")\n",
        "id_df = pd.read_csv(data_url)\n",
        "\n",
        "id_df = id_df.set_index('image')\n",
        "id_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "# excel on mac corrupts the IDs (no need to do this on PC or linux)\n",
        "id_df['individual_id'] = id_df['individual_id'].apply(\n",
        "    lambda x: str(int(float(x))) if 'E+' in str(x) else x\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicting IDs\n",
        "\n",
        "We're also going to peek under the hood of [identify.predict_ids](api/identify.predict_ids.qmd). This is helpful because the number of proposed IDs will vary a lot with such a large and diverse dataset as the Happywhale dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyseter.identify import find_neighbors, insert_new_id, pool_predictions\n",
        "import numpy as np\n",
        "\n",
        "# this is the true id of every id in the reference dataset\n",
        "ids = id_df.loc[reference_files, 'individual_id'].to_numpy()\n",
        "\n",
        "# takes about 19 seconds\n",
        "distance_matrix, index_matrix = find_neighbors(reference_features, query_features)\n",
        "\n",
        "# get the corresponding labels for each reference image\n",
        "predicted_ids = ids[index_matrix]\n",
        "\n",
        "# insert the prediction \"new_individual\" at the threshold\n",
        "distances, ids = insert_new_id(distance_matrix, predicted_ids, threshold=0.5)\n",
        "\n",
        "# remove redundant predictions and take the minimum distance \n",
        "pooled_distances, pooled_ids = pool_predictions(ids, distances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we want to find where in the `pooled_ids` is the true identity of the animal. If the algorithm's first guess was right, then this value should be `1`. As such, we are finding the rank of the correct guess for each query image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "records = []\n",
        "for i, image in enumerate(query_files):\n",
        "\n",
        "    # where is the true id in the list of predicted IDs?\n",
        "    true_id = id_df.loc[image]['individual_id']\n",
        "    rank = where(pooled_ids[i].tolist(), true_id)\n",
        "\n",
        "    # these will become the rows in our dataframe\n",
        "    records.append({'image': image, 'rank': rank})\n",
        "\n",
        "df = pd.DataFrame.from_records(records).set_index('image').join(id_df)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So in the case of the dusky dolphin image, `0df089463bfd6b.jpg`, the algorithm's first two guesses were that this individual was in the reference set, when in reality it was new to the reference set.\n",
        "\n",
        "## Computing false negative rates\n",
        "\n",
        "Now we want to understand what our false negative rate would have been had we tried different strategies. These strategies, `proposed_id_count`, correspond to the arguments between the AI skeptic and the AI optimist. At one extreme, we only look at the first proposed ID. At the other, we look through the first 25 proposed IDs. Here, we assume that there are no false positive matches. \n",
        "\n",
        "For fun, we'll look at the average across species. Note that this is a naive approach, because the algorithm's performance can vary widely across catalogs for the same species [@patton-2023-deep]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_list = []\n",
        "\n",
        "# how many of the proposed ids did you check?\n",
        "for proposed_id_count in range(1, 26):\n",
        "\n",
        "    # was the true id further down the list?\n",
        "    # i.e., had you kept looking would you have found it?\n",
        "    missed_match = df['rank'] > proposed_id_count\n",
        "\n",
        "    # is this individual in the reference set? we're assuming no false positives\n",
        "    not_new = df['individual_id'] != 'new_individual'\n",
        "\n",
        "    # if both are true, then you committed a false negative error\n",
        "    df['error'] = missed_match & not_new\n",
        "\n",
        "    # compute the average for each species \n",
        "    fn_df = df.groupby('species')['error'].mean().rename('fn_rate').reset_index()\n",
        "    fn_df['proposed_id_count'] = proposed_id_count\n",
        "    \n",
        "    df_list.append(fn_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can translate these false negative rates into expected relative bias in our estimate of the total population size. A relative bias of 10% means that we overestimate the population by 10%. For every one percentage point increase in the false negative rate, our relative bias increases by 2.56 percentage points [@patton-2025-optimizing]. We're going to exclude the Fraser's dolphin catalog, which had extremely poor performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fn_df = pd.concat(df_list)\n",
        "fn_df['rbias'] = fn_df['fn_rate'] * 2.56\n",
        "fn_df = fn_df.loc[fn_df['species'] != 'frasiers_dolphin'].reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can plot the results for each species. We've highlighted five randomly selected species to reduce over plotting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| \n",
        "specials = fn_df.sample(5, random_state=10).species.unique()\n",
        "special_df = fn_df.loc[fn_df.species.isin(specials)]\n",
        "nonspecial_df = fn_df.loc[~fn_df.species.isin(specials)]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (7, 5), tight_layout=True)\n",
        "\n",
        "for name, df in nonspecial_df.groupby('species'):\n",
        "    ax.plot(df.proposed_id_count, df.rbias, alpha=0.3, c='tab:grey', zorder=-2)\n",
        "\n",
        "for name, df in special_df.groupby('species'):\n",
        "    ax.plot(df.proposed_id_count, df.rbias, label=name.replace('_', ' '), linewidth=2.5)\n",
        "\n",
        "import matplotlib.ticker as mtick\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
        "\n",
        "ax.set_ylabel(r'Relative bias in $N$', fontsize=14)\n",
        "ax.set_xlabel(r'Proposed IDs checked', fontsize=14)\n",
        "ax.set_ylim((0, 0.6))\n",
        "\n",
        "ax.spines[:].set_visible(False)\n",
        "\n",
        "ax.xaxis.tick_bottom()\n",
        "ax.yaxis.tick_left()\n",
        "\n",
        "ax.grid(True, 'major', 'both', ls='--', lw=.5, c='k', alpha=.3)\n",
        "\n",
        "ax.tick_params(axis='both', which='both', labelsize='large',\n",
        "               bottom=False, top=False, labelbottom=True,\n",
        "               left=False, right=False, labelleft=True)\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that most species get below 10% once we've checked up to 10 proposed matches. In fact, 26 of the 39 datasets achieved a relative bias less than 10% at 10 proposed matches [@patton-2025-optimizing]. \n",
        "\n",
        "One important caveat that could be depressing performance is that, in this case, we're matching against all species. As such, the 8th, 9th, 10th, proposed ID for a long-finned pilot whale may indeed by a short-finned pilot whale. In real life, biologists will know not to match against the wrong species. Correcting for this would decrease the false negative rate for all species. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyseter)",
      "language": "python",
      "name": "pyseter_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}