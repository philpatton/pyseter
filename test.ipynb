{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4ce99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyseter.sort import load_features, prep_images\n",
    "\n",
    "root = '/Users/philtpatton/datasets/guiana/Guiana dolphins 24_25'\n",
    "image_dir = root + '/IG'\n",
    "# prep_images(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25aee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_path = root + '/features/ig_features.npy'\n",
    "feature_dict = np.load(feature_path, allow_pickle=True).item()\n",
    "\n",
    "# unpack the dictionary into arrays\n",
    "filenames = np.array(list(feature_dict.keys()))\n",
    "feature_array = np.array(list(feature_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b36c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1190 clusters.\n",
      "Largest cluster has 5443 images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pyseter.sort import report_cluster_results, format_ids\n",
    "\n",
    "# convert similarity threshold to distance\n",
    "match_threshold = 0.75\n",
    "distance_threshold = 1 - match_threshold\n",
    "\n",
    "dist_matrix = 1 - cosine_distances(feature_array)\n",
    "# cluster using average linkage\n",
    "hac_average = AgglomerativeClustering(\n",
    "    n_clusters=None, \n",
    "    distance_threshold=distance_threshold, \n",
    "    linkage='average',\n",
    "    metric='precomputed'\n",
    ").fit(dist_matrix)\n",
    "labels_average = hac_average.labels_\n",
    "report_cluster_results(labels_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b2bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 clusters.\n",
      "Largest cluster has 53 images.\n"
     ]
    }
   ],
   "source": [
    "# single linkage is necessary when using cosine distance\n",
    "distance_threshold = 0.5\n",
    "hac_complete = AgglomerativeClustering(\n",
    "    distance_threshold=distance_threshold, \n",
    "    n_clusters=None, \n",
    "    metric='cosine', \n",
    "    linkage='complete'\n",
    ").fit(feature_array)\n",
    "labels_complete = hac_complete.labels_\n",
    "report_cluster_results(labels_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d9cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philtpatton/source/repos/pyseter/pyseter/grade.py:15: UserWarning: Distinctiveness grades are experimental and should be verified.\n",
      "  warn('Distinctiveness grades are experimental and should be verified.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognizable identity cluster consists of 1120 images.\n"
     ]
    }
   ],
   "source": [
    "from pyseter.grade import rate_distinctiveness\n",
    "ers = rate_distinctiveness(feature_array, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9384b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ers_df = pd.DataFrame(dict(image=filenames, ers=ers))\n",
    "\n",
    "autosort_dir = root + '/IG_autosort'\n",
    "file_id_map = {}\n",
    "for path, _, files in os.walk(autosort_dir):\n",
    "    for file in files:\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "        full_path = os.path.join(path, file)\n",
    "        id_folder = full_path.split('/')[-3]\n",
    "        file_id_map[file] = id_folder\n",
    "       \n",
    "ers_df['autosort_id'] = [file_id_map[f] for f in ers_df.image]\n",
    "id_ers = ers_df.groupby('autosort_id')['ers'].median().rename('id_ers').reset_index()\n",
    "ers_df = ers_df.merge(id_ers)[['autosort_id', 'id_ers', 'image', 'ers']].sort_values('autosort_id').reset_index(drop=True)\n",
    "\n",
    "out_path = root + '/ig_ers.csv'\n",
    "ers_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f298c90",
   "metadata": {},
   "source": [
    "# SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d726448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philtpatton/source/repos/pyseter/pyseter/grade.py:15: UserWarning: Distinctiveness grades are experimental and should be verified.\n",
      "  warn('Distinctiveness grades are experimental and should be verified.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognizable identity cluster consists of 1279 images.\n"
     ]
    }
   ],
   "source": [
    "image_dir = root + '/SE'\n",
    "# prep_images(root)\n",
    "\n",
    "feature_path = root + '/features/se_features.npy'\n",
    "feature_dict = np.load(feature_path, allow_pickle=True).item()\n",
    "\n",
    "# unpack the dictionary into arrays\n",
    "filenames = np.array(list(feature_dict.keys()))\n",
    "feature_array = np.array(list(feature_dict.values()))\n",
    "\n",
    "ers = rate_distinctiveness(feature_array, 0.75)\n",
    "\n",
    "ers_df = pd.DataFrame(dict(image=filenames, ers=ers))\n",
    "\n",
    "autosort_dir = root + '/SE_autosort'\n",
    "file_id_map = {}\n",
    "for path, _, files in os.walk(autosort_dir):\n",
    "    for file in files:\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "        full_path = os.path.join(path, file)\n",
    "        id_folder = full_path.split('/')[-3]\n",
    "        file_id_map[file] = id_folder\n",
    "       \n",
    "ers_df['autosort_id'] = [file_id_map[f] for f in ers_df.image]\n",
    "id_ers = ers_df.groupby('autosort_id')['ers'].median().rename('id_ers').reset_index()\n",
    "ers_df = ers_df.merge(id_ers)[['autosort_id', 'id_ers', 'image', 'ers']].sort_values('autosort_id').reset_index(drop=True)\n",
    "\n",
    "out_path = root + '/se_ers.csv'\n",
    "ers_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
