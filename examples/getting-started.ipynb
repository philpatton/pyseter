{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151bb889-283e-4969-8228-ef94ab299dde",
   "metadata": {},
   "source": [
    "# Getting started with Pyseter\n",
    "\n",
    "Pyseter is an Python package for sorting images by an automatically generated ID. The main functions of Pyseter are:\n",
    "\n",
    "1. Extracting features from images\n",
    "2. Clustering images by proposed ID\n",
    "3. Sorting images by cluster\n",
    "4. Grading images by distinctiveness\n",
    "\n",
    "This notebook will walk you through each major function. First, let's make sure that pyseter is properly installed, and that it can access Pytorch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b682038-990e-4ee6-b4ce-a4e8ec3d77b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch 2.7.1+cu126 detected\n",
      "✓ CUDA GPU available: NVIDIA H200 NVL\n"
     ]
    }
   ],
   "source": [
    "import pyseter\n",
    "\n",
    "pyseter.verify_pytorch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3043bd-ace5-4acb-b72d-53b62ae85583",
   "metadata": {},
   "source": [
    "If you're on a Mac, you should see something like\n",
    "\n",
    "```\n",
    "✓ PyTorch 2.7.0 detected\n",
    "✓ Apple Silicon (MPS) GPU available\n",
    "```\n",
    "\n",
    "Please note, however, that *AnyDorsal* consumes quite a bit of memory. As such, only Apple Silicon devices with 16 GB or more of memory will work. Ideally, future versions of Pyseter will use a smaller model.\n",
    "\n",
    "If neither Apple Silicon or an NVIDIA GPU are available, you will see a message like this.\n",
    "\n",
    "```\n",
    "✓ PyTorch 2.7.1+cu126 detected\n",
    "! No GPU acceleration available. Expect slow feature extraction.\n",
    "```\n",
    "\n",
    "**A note for R users** In R, the above code block would look something like\n",
    "\n",
    "```\n",
    "library(pyseter)\n",
    "verify_pytorch()\n",
    "```\n",
    "\n",
    "or, \n",
    "\n",
    "```\n",
    "pyseter::verify_pytorch()\n",
    "```\n",
    "\n",
    "Imports work a little differently in Python. First, we need tell Python that this package is available for imports, `import pyseter`, then we need to explicitly call the function from the library `pyseter.verify_pytorch()`. To an R user, this can feel overly wordy. Nevertheless, this wordiness helps keep the global environment clean. Whereas R sessions frequently have to deal with [masking names](https://adv-r.hadley.nz/functions.html?q=masking#lexical-scoping), this rarely happens in Python. \n",
    "\n",
    "## Folder management\n",
    "\n",
    "The main purpose of pyseter is organizing images into folders. To do keep things clean and tidy, we recommend establishing a `working directory` with a subfolder, e.g., called, `all images`, that contains every image you want to be sorted (see below for a different case). Optionally, you might want to have a .csv with encounter information in the working directory. This .csv would contain two columns: one for the image name, i.e., every image in `all images`, and another for the encounter. As such, the working directory would look like this. \n",
    "\n",
    "```\n",
    "working directory\n",
    "├── encounter_info.csv\n",
    "├── all images\n",
    "│   └──00cef32dc62b0f.jpg\n",
    "│   └──3ecc025ea6f9bf.jpg\n",
    "│   └──9f18762a48696b.jpg\n",
    "│   └──36f78517a512dd.jpg\n",
    "│   └──470d524b4d5303.jpg\n",
    "       ...\n",
    "│   └──4511c9e5cb7acb.jpg\n",
    "```\n",
    "\n",
    "### Optional: prep_images\n",
    "\n",
    "Sometimes, you might have your images organized into subfolders by encounter. \n",
    "\n",
    "```\n",
    "working_dir\n",
    "└── original_images\n",
    "    ├── SL_HI_006_20220616 (CROPPED)\n",
    "    │   ├── 2022-06-16_CLD500_CL_006.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_007.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_008.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_021.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_042.JPG\n",
    "...\n",
    "    ├── SL_HI_007_20220616 (CROPPED)\n",
    "    │   ├── 2022-06-16_CLD500_CL_346.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_347.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_371.JPG\n",
    "    │   ├── 2022-06-16_CLD500_CL_372.JPG\n",
    "```\n",
    "\n",
    "In this case, you might want to accomplish two tasks: move all these images to one folder, and create a .csv that indicates which image belongs to which encounter (i.e., a map from image to encounter). The `prep_images()` function does just that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f46f939-2856-46be-add5-2d42796ce817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 1230 images to: /home/pattonp/koa_scratch/id_data/working_dir/all_images\n",
      "Saved encounter information to: /home/pattonp/koa_scratch/id_data/working_dir/original_images/encounter_info.csv\n"
     ]
    }
   ],
   "source": [
    "from pyseter.sort import prep_images\n",
    "\n",
    "# various directories we'll be working with\n",
    "working_dir = '/home/pattonp/koa_scratch/id_data/working_dir'\n",
    "original_image_dir = working_dir + '/original_images'\n",
    "\n",
    "# new directory containing every image\n",
    "image_dir = working_dir + '/all_images'\n",
    "\n",
    "prep_images(original_image_dir, all_img_dir=image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ed5d5",
   "metadata": {},
   "source": [
    "**A note for R users** In python, you can concatenate strings with the `+` operator. This is equivalent to `paste0(working_dir, '/original_images')` in R.   \n",
    "\n",
    "**A note for R users** Packages in Python tend to be subdivided into modules based on their functions. In pyseter, the `sort` module contains functions for sorting files, including other forms of file management. \n",
    "\n",
    "## Extracting features\n",
    "\n",
    "Pyseter extracts *feature vectors* for every image with [AnyDorsal](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14167), an algorithm for identifying whales and dolphins of many species. Feature vectors summarize three-dimensional images into one-dimensional vectors that are useful for the task at hand, in this case, individual identification. \n",
    "\n",
    "Before we extract the feature vectors, let's first create a subfolder within our working directory to save them in. This isn't necessary, yet keeps things tidy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e70d3d-832d-4a24-aa75-0b8a831a973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# in case you want to save the features after extracting them \n",
    "feature_dir = working_dir + '/features'\n",
    "os.makedirs(feature_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caddbf",
   "metadata": {},
   "source": [
    "\n",
    "**A note for R users**  The module, `os`,  is part of Python's *standard library*. People often refer to R and its standard libraries as \"base R.\" Base R includes the stats library, which provides the function `rnorm`. The `os` module has many functions for tinkering with your operating system. \n",
    "\n",
    "We will extract features with the `FeatureExtractor` class. To do so, we first need to initialize the class. This sets up important parameters, such as the `batch_size`, which is the number of images that will be processed in parallel. Larger batches should run faster, although your mileage may vary. If you specify too large of a batch, you may encounter an `OutOfMemoryError` (see below for an example). If you encounter this error, try specifying a larger batch size. If you encounter this error with a very small batch size (say, 2), you may need to resize your images. You can do this manually by reducing the file size in an image editing software, or [with Python](https://imagekit.io/blog/image-resizing-in-python/)\n",
    "\n",
    "```\n",
    "OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 5.81 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 5.76 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 50.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
    "```\n",
    "\n",
    "**A note for R users** Python error messages are comically long, putting CVS receipts to shame. This is because they show the entire traceback, i.e., this error caused this error caused this error, etc. To quickly diagnose the problem, scroll to the bottom of the message. Then, you can further dissect it by scrolling up.\n",
    "\n",
    "The second parameter is the `model_path`, which is the full path to the *AnyDorsal* model weights. T0D0: We have to find somewhere to host these weights, and to get permission from Ted since they are a Happywhale product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c85063-614a-433d-8bdb-867c8c965122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda (NVIDIA H200 NVL)\n"
     ]
    }
   ],
   "source": [
    "from pyseter.extract import FeatureExtractor\n",
    "\n",
    "# specify the configuration for the extractor \n",
    "fe = FeatureExtractor(\n",
    "    batch_size=4,\n",
    "    model_path='/home/pattonp/ristwhales/ristwhales_model.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f61bb-8529-440b-a9c3-b9a7bbd9526e",
   "metadata": {},
   "source": [
    "Once we've initialize the class, we can use its associated methods (functions). In this case, the only one we are interested in is `extract()`, which extracts a feature vector for every image in a specified directory. This can take several minutes, so we typically save the results afterwards. \n",
    "\n",
    "**A note for R users** Classes and methods also exist in R, but operate more behind the scenes. For example, `x <- data.frame()` initializes an object of class data.frame, and `summary(x)` calls the summary method for data.frames. Python makes this relationship more explicit. For example, the equivalent (although non-sensical) Python code would be `x = data.frame()` and `x.summary()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff8c63c-3268-44b6-8703-66fcb03b6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading model from: /home/pattonp/ristwhales/ristwhales_model.pth\n",
      "Warning: Missing keys when loading pretrained weights: ['head.weight']\n",
      "Warning: Unexpected keys when loading pretrained weights: ['head.fc.weight']\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/home/pattonp/koa_scratch/id_data/working_dir/all_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotADirectoryError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# extract the features for the input directory then save them\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m features = fe.extract(image_dir=image_dir)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# this saves them as an numpy array\u001b[39;00m\n\u001b[32m      7\u001b[39m out_path = feature_dir + \u001b[33m'\u001b[39m\u001b[33m/features.npy\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pyseter/lib/python3.13/site-packages/pyseter/extract.py:139\u001b[39m, in \u001b[36mFeatureExtractor.extract\u001b[39m\u001b[34m(self, image_dir)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stochastic:\n\u001b[32m    137\u001b[39m     model.eval()\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m test_dataloader = get_test_data(image_dir, \u001b[38;5;28mself\u001b[39m.batch_size, \u001b[38;5;28mself\u001b[39m.bbox_csv)\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mExtracting features...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    142\u001b[39m features = \u001b[38;5;28mself\u001b[39m.extract_features(test_dataloader, model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pyseter/lib/python3.13/site-packages/pyseter/extract.py:383\u001b[39m, in \u001b[36mget_test_data\u001b[39m\u001b[34m(directory, batch_size, bbox_csv)\u001b[39m\n\u001b[32m    375\u001b[39m image_size = (\u001b[32m768\u001b[39m, \u001b[32m768\u001b[39m)\n\u001b[32m    377\u001b[39m data_transforms = v2.Compose([\n\u001b[32m    378\u001b[39m     v2.Resize(image_size),\n\u001b[32m    379\u001b[39m     v2.ToDtype(torch.float32, scale=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    380\u001b[39m     v2.Normalize(rgb_mean.tolist(), rgb_std.tolist()),\n\u001b[32m    381\u001b[39m ])\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m test_data = DorsalImageDataset(directory, transform=data_transforms, \n\u001b[32m    384\u001b[39m                               bbox_csv=bbox_csv)\n\u001b[32m    386\u001b[39m dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m    387\u001b[39m                        num_workers=\u001b[32m2\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pyseter/lib/python3.13/site-packages/pyseter/extract.py:348\u001b[39m, in \u001b[36mDorsalImageDataset.__init__\u001b[39m\u001b[34m(self, image_dir, transform, bbox_csv)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28mself\u001b[39m.image_dir = image_dir\n\u001b[32m    347\u001b[39m \u001b[38;5;28mself\u001b[39m.transform = transform\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[38;5;28mself\u001b[39m.images = list_images(image_dir)\n\u001b[32m    349\u001b[39m \u001b[38;5;28mself\u001b[39m.bboxes = load_bounding_boxes(bbox_csv) \u001b[38;5;28;01mif\u001b[39;00m bbox_csv \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pyseter/lib/python3.13/site-packages/pyseter/extract.py:396\u001b[39m, in \u001b[36mlist_images\u001b[39m\u001b[34m(image_dir)\u001b[39m\n\u001b[32m    393\u001b[39m images = []\n\u001b[32m    394\u001b[39m formats = (\u001b[33m'\u001b[39m\u001b[33mpng\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjpeg\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os.listdir(image_dir):\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file.lower().endswith(formats):\n\u001b[32m    398\u001b[39m         images.append(file)\n",
      "\u001b[31mNotADirectoryError\u001b[39m: [Errno 20] Not a directory: '/home/pattonp/koa_scratch/id_data/working_dir/all_images'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# extract the features for the input directory then save them\n",
    "features = fe.extract(image_dir=image_dir)\n",
    "\n",
    "# this saves them as an numpy array\n",
    "out_path = feature_dir + '/features.npy'\n",
    "np.save(out_path, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af40402-c258-4598-a2d4-94be0e9aeb52",
   "metadata": {},
   "source": [
    "The object `features` is a dictionary, whose keys are the filenames and whose values are the feature vectors associated with each filename. This helps ensure that each image is associated with the correct feature vector. Nevertheless, it can be easier to work with actual numpy arrays. To do so, convert the keys to a list, then to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bb733-aad3-4cee-909a-f6e6ddcf5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = np.array(list(features.keys()))\n",
    "feature_array = np.array(list(features.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de4530-d2d0-43cd-8387-8b5d396a6a04",
   "metadata": {},
   "source": [
    "**A note for R users** The equivalent of a dictionary in R is a named vector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c17f3-9302-42d3-90cc-b28159e41fd1",
   "metadata": {},
   "source": [
    "## Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17fa39-048f-41ee-a49d-3b782ee389de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we want to subdivide the clusters by encounter for easier viewing\n",
    "bay1_encounter_info = pd.read_csv(image_root + '/IG_identifications.csv')\n",
    "bay1_encounter_info.columns = ['image', 'encounter']\n",
    "bay1_encounter_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9495f97-18bc-443c-9765-339f20387ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyseter.sort import cluster_images, format_ids, report_cluster_results\n",
    "\n",
    "# set up the configuration for the clustering algorithm\n",
    "cluster_algorithm = 'hac'\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "# cluster away! \n",
    "results = cluster_images(bay1_feature_array, cluster_algorithm, similarity_threshold)\n",
    "cluster_ids_hac = format_ids(results)\n",
    "\n",
    "# quick summary of the clustering results\n",
    "report_cluster_results(cluster_ids_hac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc22d1e8-e1dd-4367-b8e6-c5fa65a1fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 clusters.\n",
      "Largest cluster has 53 images.\n"
     ]
    }
   ],
   "source": [
    "from pyseter.sort import report_cluster_results\n",
    "\n",
    "# quick summary of the clustering results\n",
    "report_cluster_results(cluster_ids_hac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "638860fc-994f-4b1c-990f-a5ae49586aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>autosort_id</th>\n",
       "      <th>encounter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG_2024_04_25_G1_IMG_7800_1.jpg</td>\n",
       "      <td>ID-0485</td>\n",
       "      <td>IG_2024_04_25_G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IG_2024_04_30_G1_IMG_6212_1.jpg</td>\n",
       "      <td>ID-0353</td>\n",
       "      <td>IG_2024_04_30_G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IG_2025_03_26_G6_IMG_5982_1.jpg</td>\n",
       "      <td>ID-0009</td>\n",
       "      <td>IG_2025_03_26_G6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IG_2025_04_03_G2_IMG_2495_1.jpg</td>\n",
       "      <td>ID-0269</td>\n",
       "      <td>IG_2025_04_03_G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IG_2024_05_07_G1_IMG_5733_1.jpg</td>\n",
       "      <td>ID-1132</td>\n",
       "      <td>IG_2024_05_07_G1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image autosort_id         encounter\n",
       "0  IG_2024_04_25_G1_IMG_7800_1.jpg     ID-0485  IG_2024_04_25_G1\n",
       "1  IG_2024_04_30_G1_IMG_6212_1.jpg     ID-0353  IG_2024_04_30_G1\n",
       "2  IG_2025_03_26_G6_IMG_5982_1.jpg     ID-0009  IG_2025_03_26_G6\n",
       "3  IG_2025_04_03_G2_IMG_2495_1.jpg     ID-0269  IG_2025_04_03_G2\n",
       "4  IG_2024_05_07_G1_IMG_5733_1.jpg     ID-1132  IG_2024_05_07_G1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe proposed id and encounter for each image\n",
    "hac_df = pd.DataFrame({'image': bay1_filenames, 'autosort_id': cluster_ids_hac})\n",
    "hac_df = hac_df.merge(bay1_encounter_info)\n",
    "\n",
    "hac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "babf447f-c801-4a5f-9412-7e148db68b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted 7306 images into 2602 folders.\n"
     ]
    }
   ],
   "source": [
    "from pyseter.sort import sort_images\n",
    "\n",
    "bay1_out = image_root + '/IG_autosort'\n",
    "sort_images(hac_df, bay1_dir, bay1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c01abd70-0498-4786-9dcc-da58f398e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to subdivide the clusters by encounter for easier viewing\n",
    "bay2_encounter_info = pd.read_csv(image_root + '/SE_identifications.csv')\n",
    "bay2_encounter_info.columns = ['image', 'encounter']\n",
    "\n",
    "bay2_filenames = np.array(list(bay2_features.keys()))\n",
    "bay2_feature_array = np.array(list(bay2_features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "784107c3-b25c-4d12-8856-772faa0b4a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 6297 features with Hierachical Clustering.\n",
      "Found 1005 clusters.\n",
      "Largest cluster has 66 images.\n"
     ]
    }
   ],
   "source": [
    "# cluster away! \n",
    "results = cluster_images(bay2_feature_array, cluster_algorithm, similarity_threshold)\n",
    "cluster_ids_hac = format_ids(results)\n",
    "\n",
    "# quick summary of the clustering results\n",
    "report_cluster_results(cluster_ids_hac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d180e8-f031-49a4-af3a-1887194d4416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>autosort_id</th>\n",
       "      <th>encounter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SE_2025_04_28_G1_IMG_7314_1.jpg</td>\n",
       "      <td>ID-0071</td>\n",
       "      <td>SE_2025_04_28_G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SE_2024_05_10_G3_IMG_6609_1.jpg</td>\n",
       "      <td>ID-0908</td>\n",
       "      <td>SE_2024_05_10_G3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SE_2024_04_22_G1_IMG_1275_3.jpg</td>\n",
       "      <td>ID-0924</td>\n",
       "      <td>SE_2024_04_22_G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE_2024_05_10_G1_IMG_4130_1.jpg</td>\n",
       "      <td>ID-0328</td>\n",
       "      <td>SE_2024_05_10_G1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE_2025_04_28_G1_IMG_6897_1.jpg</td>\n",
       "      <td>ID-0021</td>\n",
       "      <td>SE_2025_04_28_G1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image autosort_id         encounter\n",
       "0  SE_2025_04_28_G1_IMG_7314_1.jpg     ID-0071  SE_2025_04_28_G1\n",
       "1  SE_2024_05_10_G3_IMG_6609_1.jpg     ID-0908  SE_2024_05_10_G3\n",
       "2  SE_2024_04_22_G1_IMG_1275_3.jpg     ID-0924  SE_2024_04_22_G1\n",
       "3  SE_2024_05_10_G1_IMG_4130_1.jpg     ID-0328  SE_2024_05_10_G1\n",
       "4  SE_2025_04_28_G1_IMG_6897_1.jpg     ID-0021  SE_2025_04_28_G1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe proposed id and encounter for each image\n",
    "hac_df = pd.DataFrame({'image': bay2_filenames, 'autosort_id': cluster_ids_hac})\n",
    "hac_df = hac_df.merge(bay2_encounter_info)\n",
    "\n",
    "hac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de1f61b1-75cd-4682-a31f-4b114f14fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted 6297 images into 2320 folders.\n"
     ]
    }
   ],
   "source": [
    "bay2_out = image_root + '/SE_autosort'\n",
    "sort_images(hac_df, bay2_dir, bay2_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyseter)",
   "language": "python",
   "name": "pyseter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
